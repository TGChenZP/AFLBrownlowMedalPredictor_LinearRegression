{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script 4. Training and collecting statistics from Linear Regression Models in two-steps with Bootstrapping #\n",
    "## For Brownlow Predictor Project ##\n",
    "\n",
    "Trains and collects statistics from 4000 different LR Models in two-steps wth Bootstrapping for Brownlow Predicting\n",
    "\n",
    "Different models arise from the permutations of choices one can make when training models. For this case they are:\n",
    "- [x] 5 Data Manipulation Types\n",
    "- [x] 3 Values of Adjusted Votes for labels of step 1\n",
    "- [x] 4 Macro Rules of Feature Selection \n",
    "- [x] 4 Feature Selection Coefficient Cutoff Values \n",
    "- [x] 4 Micro Rules of Feature Selection\n",
    "- [x] 2 Whether to include Winloss in columns\n",
    "- [x] (5 Folds of Train-Test Split)\n",
    "\n",
    "\n",
    "**Author: `Lang (Ron) Chen` 2021.12-2022.1**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "from BrownlowPredictorTools2.predict import predict1_mass, predict2_mass\n",
    "from BrownlowPredictorTools2.test import test1_mass, test2_mass\n",
    "from BrownlowPredictorTools2.wholeseason import wholeseason\n",
    "from BrownlowPredictorTools.feature_selection2 import feature_selection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Central_Statistics = pd.read_csv('Central_Statistics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Using Loops to simulate permutations**\n",
    "\n",
    "*Makes clever use of f-strings to input and output the desired data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10h 26min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "choice = {'N': 'NormalisedData', 'S': 'StandardisedData', 'RS': 'RankStandardisedData', \n",
    "          'P': 'PercentageData', 'PN': 'PercentageNormalisedData'}\n",
    "\n",
    "for dt in ['N', 'S', 'RS', 'P', 'PN']: # 5 Data Manipulation Types\n",
    "    \n",
    "    filelist = os.listdir(f'./Data/{choice[dt]}')[1:]\n",
    "    \n",
    "    # Gets list of emperical test games (full 2021 season)\n",
    "    final_test_games = [file for file in filelist if '2021' in file]\n",
    "    \n",
    "    for adj_votes in range(1, 4): # 3 Adjusted Vote Values to use for labels of step-one\n",
    "    \n",
    "        for use in ['BT', 'OT', 'BT_OT', 'BT+OT']:\n",
    "            \n",
    "            # BT: Both Teams\n",
    "            # OT: Own Team\n",
    "            # BT_OT: Both Teams data OR Own Team data (same stat cannot use both columns)\n",
    "            # BT+OT: Both Teams data AND Own Team data (free to use both columns for same stats)\n",
    "            \n",
    "            BT_OT = False # Variable to be used later in feature_selection2() function\n",
    "            if use == 'BT_OT':\n",
    "                BT_OT = True\n",
    "\n",
    "            for FS_val in [0.2, 0.25, 0.3, 0.35]: # 4 Feature Selection Coefficient Cutoff Values: Above what level of \n",
    "            # pearsons correlation coeffcient does a column have to be in order to be selected as a feature \n",
    "\n",
    "                for FS_rule in [1, 2, 3, 4]: # 4 Micro Rules of Feature Selection\n",
    "                    \n",
    "                # 1: All cols that passed FS_val selected\n",
    "                # 2: For those with dependency/triangle relationships (i.e. A=Disposals/B=Kicks/C=Handballs), if A comes first then B, C excluded. If B or C comes first then A excluded\n",
    "                # 3: All cols that passed FS_val selected but abandon all 'summary' cols such as Disposal/Tackles/Marks\n",
    "                # 4: Exclude Disposals, otherwise as per rule 2\n",
    "                \n",
    "                    for winloss in ['In', 'Out']: # 2 Whether to include Winloss in columns\n",
    "\n",
    "                        for fold in [1, 2, 3, 4, 5]: # 5 Folds of Train-Test Split\n",
    "                            \n",
    "                            # Read in appropriate Train and Test data\n",
    "                            first_lr_data = pd.read_csv(f'./PreparedData/Train_Data_{fold} ({dt}) (2_1_{adj_votes})(B).csv')\n",
    "\n",
    "                            second_lr_data = pd.read_csv(f'./PreparedData/Train_Data_{fold} ({dt}) (2_2)(B).csv')\n",
    "                            \n",
    "                            test_games = list(pd.read_csv(f'./PreparedData/Test_Games_List_{fold} ({dt}) (2)(B).csv')['Test Games'])\n",
    "                            \n",
    "                            # Primary filtering of features according to Macro Rules\n",
    "                            if use in ['BT', 'OT']:\n",
    "                                # Accounts for Winloss inclusion choice\n",
    "                                if winloss:\n",
    "                                    cols = [col for col in first_lr_data.columns if (f'{use}{dt}' in col or 'Winloss' in col)]\n",
    "                \n",
    "                                else:\n",
    "                                    cols = [col for col in first_lr_data.columns if (f'{use}{dt}' in col)]\n",
    "\n",
    "                            else:\n",
    "                                # Accounts for Winloss inclusion choice\n",
    "                                if winloss:\n",
    "                                    cols = [col for col in first_lr_data.columns if (f'BT{dt}' in col or f'OT{dt}' in col or 'Winloss' in col)]\n",
    "\n",
    "                                else:\n",
    "                                    cols = [col for col in first_lr_data.columns if (f'BT{dt}' in col or f'OT{dt}' in col)]\n",
    "                            \n",
    "                            # Calculates correlation and only accept columns that have surpassed FS_Val\n",
    "                            corr1 = dict()\n",
    "                            corr2 = dict()\n",
    "                            for col in cols:\n",
    "                                corr1[col] = first_lr_data[[col, 'Brownlow Votes']].corr(method = 'pearson').loc[col]['Brownlow Votes']\n",
    "                                corr2[col] = second_lr_data[[col, 'Brownlow Votes']].corr(method = 'pearson').loc[col]['Brownlow Votes']\n",
    "\n",
    "                            corr1 = list(corr1.items())\n",
    "                            corr2 = list(corr2.items())\n",
    "        \n",
    "                            selected_features1 = [col[0] for col in corr1 if col[1] > FS_val]\n",
    "                            selected_features2 = [col[0] for col in corr2 if col[1] > FS_val]\n",
    "\n",
    "                            # Put into feature_selection2 function to do secondary filtering based on the FS_rule and BT_OT (or not)\n",
    "                            selected_features1 = feature_selection2(selected_features1, FS_rule, BT_OT)\n",
    "                            selected_features2 = feature_selection2(selected_features2, FS_rule, BT_OT)\n",
    "                            \n",
    "                            # Initialises a blank dataframe for this test sample\n",
    "                            cent_storage_cols = {'Method': [f'LR(2)(B)_({adj_votes})'], 'Datatype': [dt], 'Use': [use], 'Feature Selection Value': [FS_val], \n",
    "                                                 'Feature Selection Rule': [FS_rule], 'Winloss': [winloss], 'Fold': [fold], 'TP0': [None], \n",
    "                                                 'TP0.5': [None], 'TP1': [None], 'TP2': [None], 'TP3': [None], 'Coef1': [None], 'Coef2': [None],\n",
    "                                                'P1': [None], 'V1': [None],\n",
    "                                                'P2': [None], 'V2': [None],\n",
    "                                                'P3': [None], 'V3': [None],\n",
    "                                                'P4': [None], 'V4': [None],\n",
    "                                                'P5': [None], 'V5': [None],\n",
    "                                                'P6': [None], 'V6': [None],\n",
    "                                                'P7': [None], 'V7': [None],\n",
    "                                                'P8': [None], 'V8': [None],\n",
    "                                                'P9': [None], 'V9': [None],\n",
    "                                                'P10': [None], 'V10': [None],\n",
    "                                                'P11': [None], 'V11': [None],\n",
    "                                                'P12': [None], 'V12': [None],\n",
    "                                                'P13': [None], 'V13': [None],\n",
    "                                                'P14': [None], 'V14': [None],\n",
    "                                                'P15': [None], 'V15': [None],\n",
    "                                                'P16': [None], 'V16': [None],\n",
    "                                                'P17': [None], 'V17': [None],\n",
    "                                                'P18': [None], 'V18': [None],\n",
    "                                                'P19': [None], 'V19': [None],\n",
    "                                                'P20': [None], 'V20': [None]}\n",
    "\n",
    "                            if not selected_features1 or not selected_features2:\n",
    "                                # Adds it onto our Dataframe for writing onto Central Database later\n",
    "                                Central_Statistics = Central_Statistics.append(pd.DataFrame(cent_storage_cols))\n",
    "                                continue\n",
    "                            \n",
    "                            # Prepare data for Training for step 1\n",
    "                            traindataf_x = first_lr_data[selected_features1]\n",
    "                            traindataf_x.index = range(len(first_lr_data))\n",
    "                            traindataf_y = first_lr_data['Brownlow Votes']\n",
    "                            traindataf_y.index = range(len(first_lr_data))\n",
    "                            \n",
    "                            # Train model for step 1\n",
    "                            lm_f = linear_model.LinearRegression()\n",
    "                            traindataf_x = traindataf_x.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "                            modelf = lm_f.fit(traindataf_x, traindataf_y)\n",
    "                            \n",
    "                            # Perform predictions and collect predictions and actual observations into one dataframe for step 1\n",
    "                            out1 = predict1_mass(test_games, lm_f, selected_features1, choice[dt])\n",
    "                            \n",
    "                            # Performs testing on test case and collect stats for true positive of 0, 1, 2 and 3 (as a tuple tp) for step 1\n",
    "                            tp1 = test1_mass(out1, adj_votes)\n",
    "\n",
    "                            # Prepare data for Training for step 2\n",
    "                            traindatas_x = second_lr_data[selected_features2]\n",
    "                            traindatas_x.index = range(0,len(second_lr_data))\n",
    "                            traindatas_y = second_lr_data['Brownlow Votes']\n",
    "                            traindatas_y.index = range(0,len(second_lr_data))\n",
    "                            \n",
    "                            # Train model for step 2 \n",
    "                            lm_s = linear_model.LinearRegression()\n",
    "                            traindatas_x = traindatas_x.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "                            models = lm_s.fit(traindatas_x, traindatas_y)\n",
    "\n",
    "                            # Perform predictions and collect predictions and actual observations into one dataframe for step 2\n",
    "                            out2 = predict2_mass(test_games, lm_s, selected_features2, choice[dt])\n",
    "                            \n",
    "                            # Performs testing on test case and collect stats for true positive of 0, 1, 2 and 3 (as a tuple tp) for step 2\n",
    "                            tp2 = test2_mass(out2)\n",
    "                            \n",
    "                            # Performs emperical testing on 2021 season\n",
    "                            leaderboard = wholeseason(final_test_games, lm_f, lm_s, selected_features1, selected_features2, choice[dt])\n",
    "                            \n",
    "                            # Collects the pearsons coefficient for this model\n",
    "                            pears_co1 = lm_f.score(traindataf_x, traindataf_y)\n",
    "                            pears_co2 = lm_s.score(traindatas_x, traindatas_y)\n",
    "\n",
    "                            # Initialises a dataframe for this test sample, beginning to fill in some of the statistics\n",
    "                            cent_storage_cols = {'Method': [f'LR(2)(B)_({adj_votes})'], 'Datatype': [dt], 'Use': [use], 'Feature Selection Value': [FS_val], \n",
    "                                                 'Feature Selection Rule': [FS_rule], 'Winloss': [winloss], 'Fold': [fold], 'TP0': [tp1[0]], \n",
    "                                                 'TP0.5': [tp1[1]], 'TP1': [tp2[0]], 'TP2': [tp2[1]], 'TP3': [tp2[2]], 'Coef1': [pears_co1], 'Coef2': [pears_co2],\n",
    "                                                'P1': list(), 'V1': list(),\n",
    "                                                'P2': list(), 'V2': list(),\n",
    "                                                'P3': list(), 'V3': list(),\n",
    "                                                'P4': list(), 'V4': list(),\n",
    "                                                'P5': list(), 'V5': list(),\n",
    "                                                'P6': list(), 'V6': list(),\n",
    "                                                'P7': list(), 'V7': list(),\n",
    "                                                'P8': list(), 'V8': list(),\n",
    "                                                'P9': list(), 'V9': list(),\n",
    "                                                'P10': list(), 'V10': list(),\n",
    "                                                'P11': list(), 'V11': list(),\n",
    "                                                'P12': list(), 'V12': list(),\n",
    "                                                'P13': list(), 'V13': list(),\n",
    "                                                'P14': list(), 'V14': list(),\n",
    "                                                'P15': list(), 'V15': list(),\n",
    "                                                'P16': list(), 'V16': list(),\n",
    "                                                'P17': list(), 'V17': list(),\n",
    "                                                'P18': list(), 'V18': list(),\n",
    "                                                'P19': list(), 'V19': list(),\n",
    "                                                'P20': list(), 'V20': list()}\n",
    "                            \n",
    "                            # Fill in emperical observations\n",
    "                            for i in range(1, 21):\n",
    "                                cent_storage_cols[f'P{i}'].append(leaderboard[i-1][0])\n",
    "                                cent_storage_cols[f'V{i}'].append(leaderboard[i-1][1])\n",
    "\n",
    "                            # Adds it onto our Dataframe for writing onto Central Database later\n",
    "                            Central_Statistics = Central_Statistics.append(pd.DataFrame(cent_storage_cols))\n",
    "                    \n",
    "                    # Write the Dataframe (consisting 10 models and their statistics) out\n",
    "                            # Chose to do it in batch of 10 to conserve computational power.\n",
    "                            # But must output regularly as the full block takes up to 10 hours to run - if fail somewhere in between need a method to salvage results.\n",
    "                    Central_Statistics.to_csv('Central_Statistics.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: A few improvements could be made on this notebook: ##\n",
    "\n",
    "*1. To further save computational time, could consider switching up order of iteration (although that may be dangerous as it doesn't guarentee we are reading correct copy in from files each time*\n",
    "\n",
    "*2. A mechanism for starting loop at predetermined point (in case fails half way - don't want to waste previous computation time). Would be useful for future projects that does mass testing*\n",
    "\n",
    "*-an idea is to perhaps try turn iterations first into a list, and then iterate through the list. Thus at failpoint, could salvage the iterator index that it was up to and restart from list[i] using list[i:].*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
