{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test Train Data Preparation #\n",
    "## For Brownlow Predictor Project ##\n",
    "\n",
    "Does 5Fold test train split for each of the 6 different types of data.\n",
    "Four different type of preparation undergone:\n",
    "- [x] Regular\n",
    "- [x] Bootstrap\n",
    "- [x] Two-Step\n",
    "- [x] Bootstrap and Two-Step\n",
    "\n",
    "and outputs them as individual .csv's.\n",
    "\n",
    "*A form of trading Time for Space: By preemptively preparing the 16GB of train-test (and manipulated otherwise) data, saves a lot of computational time when scripts are run (i.e. don't have to do test-train splits or sampling.*\n",
    "\n",
    "*Also: for the purpose of experiments maintains a controlled variable (all different models are essentially using the same rows of data for each train-split because the same seed is used*\n",
    "\n",
    "***KFold Train-Test split is used to collect better statistics for each model (i.e. each model trained five times so unlikely for a bad model to have good statistics due to luck. Split size of 5 used to ensure 1. not too many splits (computational time: adds a factor k to the permutations later on in scripts); 2. 20% data for testing (ensures a sizeable test size); 3. 80% data for training (because 3 votes 2 votes and 1 votes make up only roughly 1/15 of the rows of data, any less then 80% of training data could produce flawed results)***\n",
    "\n",
    "**Author: `Lang (Ron) Chen` 2021.12-2022.1**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: As Percentages followed by Standardisation was proven to be exactly the same as Standardisation, all relevent code have bben commented out* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Preparing Train-Test Split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choice = ['NormalisedData', 'StandardisedData', 'RankStandardisedData', 'PercentageData', 'PercentageStandardisedData', 'PercentageNormalisedData']\n",
    "choice = ['NormalisedData', 'StandardisedData', 'RankStandardisedData', 'PercentageData', 'PercentageNormalisedData']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test split done on a per-game basis because:\n",
    "1. Maintains a fixed proportion of test and train cases as 3 votes, 2 votes, 1 vote\n",
    "2. The model ultimately must be tested on a games based basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# NAME = {'NormalisedData': 'N', 'StandardisedData': 'S', 'RankStandardisedData': 'RS', 'PercentageData': 'P', \n",
    "#         'PercentageStandardisedData': 'PS', 'PercentageNormalisedData': 'PN'}\n",
    "NAME = {'NormalisedData': 'N', 'StandardisedData': 'S', 'RankStandardisedData': 'RS', 'PercentageData': 'P', 'PercentageNormalisedData': 'PN'}\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "# Each different data manipulation format needs to undergo the same train-test split\n",
    "for c in choice:\n",
    "    filelist = os.listdir(f'./Data/{c}')[1:] # Remove the first file (an ipynb checkpoint file)\n",
    "    test_train_games = [file for file in filelist if '2021' not in file] # list of games\n",
    "\n",
    "    index = 1\n",
    "    for train_games_i, test_games_i in kf.split(test_train_games): # test train split in terms of games\n",
    "        \n",
    "        train_games = [test_train_games[i] for i in train_games_i]\n",
    "        \n",
    "        test_games = [test_train_games[i] for i in test_games_i]\n",
    "        \n",
    "        # opens each file and concatenates them\n",
    "        train_data = pd.read_csv(f'./Data/{c}/{train_games[0]}')\n",
    "        \n",
    "        for file in train_games[1:]:\n",
    "            df = pd.read_csv(f'./Data/{c}/{file}')\n",
    "            train_data = pd.concat([train_data, df], axis=0)\n",
    "\n",
    "        \n",
    "        # Uses f-strings and loop variables to automatically export data as .csv's with diffent names\n",
    "        train_data.to_csv(f'Train_Data_{index} ({NAME[c]}).csv', index = False)\n",
    "        \n",
    "        \n",
    "        # Export file list of test games (literally a Series) into a csv for ease of use in scripts\n",
    "        test_game_list = pd.DataFrame({'Test Games': test_games})\n",
    "        \n",
    "        test_game_list.to_csv(f'Test_Games_List_{index} ({NAME[c]}).csv', index = False)\n",
    "\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Bootstrapped (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# NAME = {'NormalisedData': 'N', 'StandardisedData': 'S', 'RankStandardisedData': 'RS', 'PercentageData': 'P', \n",
    "#         'PercentageStandardisedData': 'PS', 'PercentageNormalisedData': 'PN'}\n",
    "NAME = {'NormalisedData': 'N', 'StandardisedData': 'S', 'RankStandardisedData': 'RS', 'PercentageData': 'P', 'PercentageNormalisedData': 'PN'}\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "# Each different data manipulation format needs to undergo the same train-test split\n",
    "for c in choice:\n",
    "    filelist = os.listdir(f'./Data/{c}')[1:] # Remove the first file (an ipynb checkpoint file)\n",
    "    test_train_games = [file for file in filelist if '2021' not in file] # list of games\n",
    "\n",
    "    index = 1\n",
    "    for train_games_i, test_games_i in kf.split(test_train_games): # test train split in terms of games\n",
    "        \n",
    "        train_games = [test_train_games[i] for i in train_games_i]\n",
    "        \n",
    "        test_games = [test_train_games[i] for i in test_games_i]\n",
    "        \n",
    "        # opens each file and concatenates them\n",
    "        train_data = pd.read_csv(f'./Data/{c}/{train_games[0]}')\n",
    "        \n",
    "        for file in train_games[1:]:\n",
    "            df = pd.read_csv(f'./Data/{c}/{file}')\n",
    "            train_data = pd.concat([train_data, df], axis=0)\n",
    "        \n",
    "        # Bootstraps data\n",
    "        \n",
    "        # Picks out data labelled 1 vote, 2 votes, 3 votes \n",
    "        zero = train_data[train_data['Brownlow Votes'] == 0]\n",
    "        one = train_data[train_data['Brownlow Votes'] == 1]\n",
    "        two = train_data[train_data['Brownlow Votes'] == 2]\n",
    "        three = train_data[train_data['Brownlow Votes'] == 3]\n",
    "        \n",
    "        # Sample them so each has same number as 0 votes\n",
    "        new_one = one.sample(n = len(zero), replace = True, random_state = 42)\n",
    "        new_two = two.sample(n = len(zero), replace = True, random_state = 42)\n",
    "        new_three = three.sample(n = len(zero), replace = True, random_state = 42)\n",
    "        \n",
    "        # Add the sampled dataframes back onto zero\n",
    "        bootstrapped_data = pd.concat([zero, new_one, new_two, new_three], axis = 0)\n",
    "        \n",
    "        \n",
    "        # Uses f-strings and loop variables to automatically export data as .csv's with diffent names\n",
    "        bootstrapped_data.to_csv(f'Train_Data_{index} ({NAME[c]}) (B).csv', index = False)\n",
    "        \n",
    "        \n",
    "        # Export file list of test games (literally a Series) into a csv for ease of use in scripts\n",
    "        test_game_list = pd.DataFrame({'Test Games': test_games})\n",
    "        \n",
    "        test_game_list.to_csv(f'Test_Games_List_{index} ({NAME[c]}) (B).csv', index = False)\n",
    "\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Two rounds (2)\n",
    "\n",
    "*Three ways to treat the >0 votes data in 1st step: assign them vote of 1 (min), vote of 2 (avg), vote of 3 (max).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GZCHE\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\GZCHE\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\GZCHE\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# NAME = {'NormalisedData': 'N', 'StandardisedData': 'S', 'RankStandardisedData': 'RS', 'PercentageData': 'P', \n",
    "#         'PercentageStandardisedData': 'PS', 'PercentageNormalisedData': 'PN'}\n",
    "NAME = {'NormalisedData': 'N', 'StandardisedData': 'S', 'RankStandardisedData': 'RS', 'PercentageData': 'P', 'PercentageNormalisedData': 'PN'}\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "# Each different data manipulation format needs to undergo the same train-test split\n",
    "for c in choice:\n",
    "    filelist = os.listdir(f'./Data/{c}')[1:] # Remove the first file (an ipynb checkpoint file)\n",
    "    test_train_games = [file for file in filelist if '2021' not in file] # list of games\n",
    "\n",
    "    index = 1\n",
    "    for train_games_i, test_games_i in kf.split(test_train_games): # test train split in terms of games\n",
    "        \n",
    "        train_games = [test_train_games[i] for i in train_games_i]\n",
    "        \n",
    "        test_games = [test_train_games[i] for i in test_games_i]\n",
    "        \n",
    "        # opens each file and concatenates them\n",
    "        train_data = pd.read_csv(f'./Data/{c}/{train_games[0]}')\n",
    "\n",
    "        for file in train_games[1:]:\n",
    "            df = pd.read_csv(f'./Data/{c}/{file}')\n",
    "            train_data = pd.concat([train_data, df], axis=0)\n",
    "        \n",
    "        # Splits data into zero votes and more than 0 votes\n",
    "        zero = train_data[train_data['Brownlow Votes'] == 0]\n",
    "        \n",
    "        # three copies because will relabel them with three different options\n",
    "        tagged1 = train_data[train_data['Brownlow Votes'] > 0]\n",
    "        tagged2 = train_data[train_data['Brownlow Votes'] > 0]\n",
    "        tagged3 = train_data[train_data['Brownlow Votes'] > 0]\n",
    "\n",
    "        tagged1['Brownlow Votes'] = tagged1['Brownlow Votes'].replace([1, 2, 3], 1)\n",
    "        tagged2['Brownlow Votes'] = tagged2['Brownlow Votes'].replace([1, 2, 3], 2)\n",
    "        tagged3['Brownlow Votes'] = tagged3['Brownlow Votes'].replace([1, 2, 3], 3)\n",
    "        \n",
    "        # concatenate them together\n",
    "        first_lr_data1 = pd.concat([zero, tagged1], axis = 0)\n",
    "        first_lr_data2 = pd.concat([zero, tagged2], axis = 0)\n",
    "        first_lr_data3 = pd.concat([zero, tagged3], axis = 0)\n",
    "\n",
    "        second_lr_data = train_data[train_data['Brownlow Votes'] > 0]\n",
    "        \n",
    "        # Export the step-1 data (3 different labels) into 3 different .csv's and also export step-2 data\n",
    "        first_lr_data1.to_csv(f'Train_Data_{index} ({NAME[c]}) (2_1_1).csv', index = False)\n",
    "        first_lr_data2.to_csv(f'Train_Data_{index} ({NAME[c]}) (2_1_2).csv', index = False)\n",
    "        first_lr_data3.to_csv(f'Train_Data_{index} ({NAME[c]}) (2_1_3).csv', index = False)\n",
    "        second_lr_data.to_csv(f'Train_Data_{index} ({NAME[c]}) (2_2).csv', index = False)\n",
    "        \n",
    "        \n",
    "        # Export file list of test games (literally a Series) into a csv for ease of use in scripts\n",
    "        test_game_list = pd.DataFrame({'Test Games': test_games})\n",
    "        \n",
    "        test_game_list.to_csv(f'Test_Games_List_{index} ({NAME[c]}) (2).csv', index = False)\n",
    "\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two Rounds + Bootstrapped (2)(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GZCHE\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\GZCHE\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\GZCHE\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# NAME = {'NormalisedData': 'N', 'StandardisedData': 'S', 'RankStandardisedData': 'RS', 'PercentageData': 'P', \n",
    "#         'PercentageStandardisedData': 'PS', 'PercentageNormalisedData': 'PN'}\n",
    "NAME = {'NormalisedData': 'N', 'StandardisedData': 'S', 'RankStandardisedData': 'RS', 'PercentageData': 'P', 'PercentageNormalisedData': 'PN'}\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "# Each different data manipulation format needs to undergo the same train-test split\n",
    "for c in choice:\n",
    "    filelist = os.listdir(f'./Data/{c}')[1:] # Remove the first file (an ipynb checkpoint file)\n",
    "    test_train_games = [file for file in filelist if '2021' not in file] # list of games\n",
    "\n",
    "    index = 1\n",
    "    for train_games_i, test_games_i in kf.split(test_train_games): # test train split in terms of games\n",
    "        \n",
    "        train_games = [test_train_games[i] for i in train_games_i]\n",
    "        \n",
    "        test_games = [test_train_games[i] for i in test_games_i]\n",
    "        \n",
    "        train_data = pd.read_csv(f'./Data/{c}/{train_games[0]}')\n",
    "\n",
    "        for file in train_games[1:]:\n",
    "            df = pd.read_csv(f'./Data/{c}/{file}')\n",
    "            train_data = pd.concat([train_data, df], axis=0)\n",
    "        \n",
    "        # Splits data into zero votes and more than 0 votes\n",
    "        zero = train_data[train_data['Brownlow Votes'] == 0]\n",
    "        \n",
    "        # three copies because will relabel them with three different options\n",
    "        tagged1 = train_data[train_data['Brownlow Votes'] > 0]\n",
    "        tagged2 = train_data[train_data['Brownlow Votes'] > 0]\n",
    "        tagged3 = train_data[train_data['Brownlow Votes'] > 0]\n",
    "\n",
    "        tagged1['Brownlow Votes'] = tagged1['Brownlow Votes'].replace([1, 2, 3], 1)\n",
    "        tagged2['Brownlow Votes'] = tagged2['Brownlow Votes'].replace([1, 2, 3], 2)\n",
    "        tagged3['Brownlow Votes'] = tagged3['Brownlow Votes'].replace([1, 2, 3], 3)\n",
    "        \n",
    "        # Bootstraps data\n",
    "        \n",
    "        # Sample them (using the same random_state (seed) outcome is the same)\n",
    "        new_tagged1 = tagged1.sample(n = len(zero), replace = True, random_state = 42)\n",
    "        new_tagged2 = tagged2.sample(n = len(zero), replace = True, random_state = 42)\n",
    "        new_tagged3 = tagged3.sample(n = len(zero), replace = True, random_state = 42)\n",
    "        \n",
    "        # concatenate them together\n",
    "        first_lr_data1 = pd.concat([zero, new_tagged1], axis = 0)\n",
    "        first_lr_data2 = pd.concat([zero, new_tagged2], axis = 0)\n",
    "        first_lr_data3 = pd.concat([zero, new_tagged3], axis = 0)\n",
    "\n",
    "        second_lr_data = train_data[train_data['Brownlow Votes'] > 0]\n",
    "        \n",
    "        # Export the step-1 data (3 different labels) into 3 different .csv's and also export step-2 data\n",
    "        first_lr_data1.to_csv(f'Train_Data_{index} ({NAME[c]}) (2_1_1)(B).csv', index = False)\n",
    "        first_lr_data2.to_csv(f'Train_Data_{index} ({NAME[c]}) (2_1_2)(B).csv', index = False)\n",
    "        first_lr_data3.to_csv(f'Train_Data_{index} ({NAME[c]}) (2_1_3)(B).csv', index = False)\n",
    "        second_lr_data.to_csv(f'Train_Data_{index} ({NAME[c]}) (2_2)(B).csv', index = False)\n",
    "        \n",
    "        \n",
    "        # Export file list of test games (literally a Series) into a csv for ease of use in scripts\n",
    "        test_game_list = pd.DataFrame({'Test Games': test_games})\n",
    "        \n",
    "        test_game_list.to_csv(f'Test_Games_List_{index} ({NAME[c]}) (2)(B).csv', index = False)\n",
    "\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: A few improvements could be made on this notebook: ##\n",
    "\n",
    "*1. An improvement to bootstrap algorithm would be i.e. for one vote to sample len(zero)-len(one) = newone, and then concat zero, one, newone, two, newtwo, three, newthree. The benefit of this is that it ensures the original rows are guarenteed to be in the training data at least once.\n",
    "    Although, it would be rather rate for a row in the original to not be sampled at all*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
