{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Concept 3. Double Linear Regression using Normalised Data/Both Teams #\n",
    "## For Brownlow Predictor Project ##\n",
    "\n",
    "Trains up 4 models using the 4 Macro Rules of Feature Selection using Normalised Data/Both Team Columns Only (FS_Val = 0.2 and Includes Winloss)\n",
    "\n",
    "Uses experimental method of doing two steps of Linear Regression: the first to pick out the three players most likely to get votes, and the second to allocate those three players 3, 2 and 1. (This Proof of Concept only demonstrates adj_votes = 2) \n",
    "\n",
    "**Author: `Lang (Ron) Chen` 2021.12-2022.1**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "from BrownlowPredictorTools2.predict import predict1, predict2\n",
    "from BrownlowPredictorTools2.test import test1, test2\n",
    "from BrownlowPredictorTools.return_tp import return_tp\n",
    "from BrownlowPredictorTools2.wholeseason import wholeseason\n",
    "from BrownlowPredictorTools.feature_selection2 import feature_selection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 'NormalisedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = os.listdir(f'./Data/{choice}')[1:]\n",
    "# Remove the first file (an ipynb checkpoint file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets list of emperical test games (full 2021 season)\n",
    "final_test_games = [file for file in filelist if '2021' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathers full games list (except 2021) and performs a single Train-Test Split (note different from previous KFold)\n",
    "test_train_games = [file for file in filelist if '2021' not in file]\n",
    "train_games, test_games = train_test_split(test_train_games, train_size = 0.8, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pre-prepared sample data of trained data only \n",
    "# (the same rows as if we used concatenated all the data from the train_games list)\n",
    "train_data = pd.read_csv('Train_Data (N).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADJ_VOTES = 2\n",
    "\n",
    "# Means replace the all rows with votes's labels (Brownlow Votes) to 2 votes (the mean).\n",
    "# Alternatives: 1 vote (min), 3 votes (max) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GZCHE\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Bootstraps data\n",
    "        \n",
    "# Picks out data labelled 1 vote, 2 votes, 3 votes \n",
    "zero = train_data[train_data['Brownlow Votes'] == 0]\n",
    "one = train_data[train_data['Brownlow Votes'] == 1]\n",
    "two = train_data[train_data['Brownlow Votes'] == 2]\n",
    "three = train_data[train_data['Brownlow Votes'] == 3]\n",
    "tagged1 = train_data[train_data['Brownlow Votes'] > 0]\n",
    "\n",
    "# Replaces votes with 2\n",
    "tagged1['Brownlow Votes'] = tagged1['Brownlow Votes'].replace([1, 2, 3], ADJ_VOTES)\n",
    "\n",
    "# Concatenates to get training data for first step of linear regression\n",
    "first_lr_data = pd.concat([zero, tagged1], axis = 0)\n",
    "\n",
    "# Concatenates to get training data for second step of linear regression\n",
    "second_lr_data = pd.concat([one, two, three], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*First LR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Disposals BTN',\n",
       " 'Marks BTN',\n",
       " 'Goals BTN',\n",
       " 'Behinds BTN',\n",
       " 'Tackles BTN',\n",
       " 'Hitouts BTN',\n",
       " 'Goal Assists BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Clangers BTN',\n",
       " 'Rebound 50s BTN',\n",
       " 'Frees For BTN',\n",
       " 'Frees Agains BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Contested Marks BTN',\n",
       " 'Marks Inside 50 BTN',\n",
       " 'One Percenters BTN',\n",
       " 'Bounces BTN',\n",
       " 'Centre Clearances BTN',\n",
       " 'Stoppage Clearances BTN',\n",
       " 'Score Involvements BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Turnovers BTN',\n",
       " 'Intercepts BTN',\n",
       " 'Tackles Inside 50 BTN',\n",
       " 'Time On Ground % BTN',\n",
       " 'Uncontested Marks BTN',\n",
       " 'Marks Outside 50 BTN',\n",
       " 'Tackles Outside 50 BTN',\n",
       " 'Behind Assists BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [col for col in first_lr_data.columns if 'BTN' in col]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Kicks BTN': 0.34254897608648405,\n",
       " 'Handballs BTN': 0.29030397576598344,\n",
       " 'Disposals BTN': 0.3967014843577754,\n",
       " 'Marks BTN': 0.17775265182547748,\n",
       " 'Goals BTN': 0.2523598064549557,\n",
       " 'Behinds BTN': 0.09662104485601558,\n",
       " 'Tackles BTN': 0.15930180626603438,\n",
       " 'Hitouts BTN': 0.02092510488870956,\n",
       " 'Goal Assists BTN': 0.12528034321935894,\n",
       " 'Inside 50s BTN': 0.2632271751903158,\n",
       " 'Clearances BTN': 0.3103631289602141,\n",
       " 'Clangers BTN': -0.12867189957860564,\n",
       " 'Rebound 50s BTN': 0.0361561147704681,\n",
       " 'Frees For BTN': 0.158697279769273,\n",
       " 'Frees Agains BTN': -0.03440033114228382,\n",
       " 'Contested Possessions BTN': 0.3570183744319988,\n",
       " 'Uncontested Possessions BTN': 0.2861417731894224,\n",
       " 'Effective Disposals BTN': 0.3600097454375318,\n",
       " 'Contested Marks BTN': 0.0923023114230299,\n",
       " 'Marks Inside 50 BTN': 0.1551229988631366,\n",
       " 'One Percenters BTN': -0.05231145263181946,\n",
       " 'Bounces BTN': 0.08086235948731897,\n",
       " 'Centre Clearances BTN': 0.2570033007396064,\n",
       " 'Stoppage Clearances BTN': 0.2731161066848122,\n",
       " 'Score Involvements BTN': 0.35169705884718977,\n",
       " 'Metres Gained BTN': 0.30240277124933446,\n",
       " 'Turnovers BTN': -0.18370150093676038,\n",
       " 'Intercepts BTN': 0.05213634947191871,\n",
       " 'Tackles Inside 50 BTN': 0.07142680488787029,\n",
       " 'Time On Ground % BTN': 0.07867901289255486,\n",
       " 'Uncontested Marks BTN': 0.153645708716318,\n",
       " 'Marks Outside 50 BTN': 0.11542215319521575,\n",
       " 'Tackles Outside 50 BTN': 0.14694285976293614,\n",
       " 'Behind Assists BTN': 0.34503221813729495,\n",
       " 'Ineffective Disposals BTN': 0.2833344057902747}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr1 = dict()\n",
    "for col in cols:\n",
    "    corr1[col] = first_lr_data[[col, 'Brownlow Votes']].corr(method = 'pearson').loc[col]['Brownlow Votes']\n",
    "corr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kicks BTN', 0.34254897608648405),\n",
       " ('Handballs BTN', 0.29030397576598344),\n",
       " ('Disposals BTN', 0.3967014843577754),\n",
       " ('Marks BTN', 0.17775265182547748),\n",
       " ('Goals BTN', 0.2523598064549557),\n",
       " ('Behinds BTN', 0.09662104485601558),\n",
       " ('Tackles BTN', 0.15930180626603438),\n",
       " ('Hitouts BTN', 0.02092510488870956),\n",
       " ('Goal Assists BTN', 0.12528034321935894),\n",
       " ('Inside 50s BTN', 0.2632271751903158),\n",
       " ('Clearances BTN', 0.3103631289602141),\n",
       " ('Clangers BTN', -0.12867189957860564),\n",
       " ('Rebound 50s BTN', 0.0361561147704681),\n",
       " ('Frees For BTN', 0.158697279769273),\n",
       " ('Frees Agains BTN', -0.03440033114228382),\n",
       " ('Contested Possessions BTN', 0.3570183744319988),\n",
       " ('Uncontested Possessions BTN', 0.2861417731894224),\n",
       " ('Effective Disposals BTN', 0.3600097454375318),\n",
       " ('Contested Marks BTN', 0.0923023114230299),\n",
       " ('Marks Inside 50 BTN', 0.1551229988631366),\n",
       " ('One Percenters BTN', -0.05231145263181946),\n",
       " ('Bounces BTN', 0.08086235948731897),\n",
       " ('Centre Clearances BTN', 0.2570033007396064),\n",
       " ('Stoppage Clearances BTN', 0.2731161066848122),\n",
       " ('Score Involvements BTN', 0.35169705884718977),\n",
       " ('Metres Gained BTN', 0.30240277124933446),\n",
       " ('Turnovers BTN', -0.18370150093676038),\n",
       " ('Intercepts BTN', 0.05213634947191871),\n",
       " ('Tackles Inside 50 BTN', 0.07142680488787029),\n",
       " ('Time On Ground % BTN', 0.07867901289255486),\n",
       " ('Uncontested Marks BTN', 0.153645708716318),\n",
       " ('Marks Outside 50 BTN', 0.11542215319521575),\n",
       " ('Tackles Outside 50 BTN', 0.14694285976293614),\n",
       " ('Behind Assists BTN', 0.34503221813729495),\n",
       " ('Ineffective Disposals BTN', 0.2833344057902747)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr1 = list(corr1.items())\n",
    "corr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Disposals BTN',\n",
       " 'Goals BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Centre Clearances BTN',\n",
       " 'Stoppage Clearances BTN',\n",
       " 'Score Involvements BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Behind Assists BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features1 = [col[0] for col in corr1 if col[1] > 0.2]\n",
    "selected_features1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Second LR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Kicks BTN': 0.16806498165519884,\n",
       " 'Handballs BTN': 0.11410782023284825,\n",
       " 'Disposals BTN': 0.19265967566658948,\n",
       " 'Marks BTN': 0.040029902523200135,\n",
       " 'Goals BTN': 0.1118167497113381,\n",
       " 'Behinds BTN': 0.06519021127478913,\n",
       " 'Tackles BTN': 0.031672694163300666,\n",
       " 'Hitouts BTN': -0.03054408421422031,\n",
       " 'Goal Assists BTN': 0.08259384485804165,\n",
       " 'Inside 50s BTN': 0.130298620435625,\n",
       " 'Clearances BTN': 0.15623123854389537,\n",
       " 'Clangers BTN': -0.025923232382053286,\n",
       " 'Rebound 50s BTN': -0.023148361144809285,\n",
       " 'Frees For BTN': 0.08207718476473534,\n",
       " 'Frees Agains BTN': -0.017991706345267772,\n",
       " 'Contested Possessions BTN': 0.19214196056197758,\n",
       " 'Uncontested Possessions BTN': 0.09103031676176843,\n",
       " 'Effective Disposals BTN': 0.17264034262690256,\n",
       " 'Contested Marks BTN': 0.0378216125045446,\n",
       " 'Marks Inside 50 BTN': 0.07494450916094313,\n",
       " 'One Percenters BTN': -0.03729972021031512,\n",
       " 'Bounces BTN': 0.036411041209316375,\n",
       " 'Centre Clearances BTN': 0.13804380527703444,\n",
       " 'Stoppage Clearances BTN': 0.13152712739654104,\n",
       " 'Score Involvements BTN': 0.24080897928650238,\n",
       " 'Metres Gained BTN': 0.14712849397144687,\n",
       " 'Turnovers BTN': -0.053104866258363304,\n",
       " 'Intercepts BTN': -0.019013816580142166,\n",
       " 'Tackles Inside 50 BTN': 0.00011001968588595914,\n",
       " 'Time On Ground % BTN': 0.012381377439194046,\n",
       " 'Uncontested Marks BTN': 0.02407864870099196,\n",
       " 'Marks Outside 50 BTN': -0.006408644251595422,\n",
       " 'Tackles Outside 50 BTN': 0.03366562096164185,\n",
       " 'Behind Assists BTN': 0.22487809147904286,\n",
       " 'Ineffective Disposals BTN': 0.11627769420949288}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2 = dict()\n",
    "for col in cols:\n",
    "    corr2[col] = second_lr_data[[col, 'Brownlow Votes']].corr(method = 'pearson').loc[col]['Brownlow Votes']\n",
    "corr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kicks BTN', 0.16806498165519884),\n",
       " ('Handballs BTN', 0.11410782023284825),\n",
       " ('Disposals BTN', 0.19265967566658948),\n",
       " ('Marks BTN', 0.040029902523200135),\n",
       " ('Goals BTN', 0.1118167497113381),\n",
       " ('Behinds BTN', 0.06519021127478913),\n",
       " ('Tackles BTN', 0.031672694163300666),\n",
       " ('Hitouts BTN', -0.03054408421422031),\n",
       " ('Goal Assists BTN', 0.08259384485804165),\n",
       " ('Inside 50s BTN', 0.130298620435625),\n",
       " ('Clearances BTN', 0.15623123854389537),\n",
       " ('Clangers BTN', -0.025923232382053286),\n",
       " ('Rebound 50s BTN', -0.023148361144809285),\n",
       " ('Frees For BTN', 0.08207718476473534),\n",
       " ('Frees Agains BTN', -0.017991706345267772),\n",
       " ('Contested Possessions BTN', 0.19214196056197758),\n",
       " ('Uncontested Possessions BTN', 0.09103031676176843),\n",
       " ('Effective Disposals BTN', 0.17264034262690256),\n",
       " ('Contested Marks BTN', 0.0378216125045446),\n",
       " ('Marks Inside 50 BTN', 0.07494450916094313),\n",
       " ('One Percenters BTN', -0.03729972021031512),\n",
       " ('Bounces BTN', 0.036411041209316375),\n",
       " ('Centre Clearances BTN', 0.13804380527703444),\n",
       " ('Stoppage Clearances BTN', 0.13152712739654104),\n",
       " ('Score Involvements BTN', 0.24080897928650238),\n",
       " ('Metres Gained BTN', 0.14712849397144687),\n",
       " ('Turnovers BTN', -0.053104866258363304),\n",
       " ('Intercepts BTN', -0.019013816580142166),\n",
       " ('Tackles Inside 50 BTN', 0.00011001968588595914),\n",
       " ('Time On Ground % BTN', 0.012381377439194046),\n",
       " ('Uncontested Marks BTN', 0.02407864870099196),\n",
       " ('Marks Outside 50 BTN', -0.006408644251595422),\n",
       " ('Tackles Outside 50 BTN', 0.03366562096164185),\n",
       " ('Behind Assists BTN', 0.22487809147904286),\n",
       " ('Ineffective Disposals BTN', 0.11627769420949288)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_corr2 = list(corr2.items())\n",
    "sort_corr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Score Involvements BTN', 'Behind Assists BTN']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features2 = [col[0] for col in sort_corr2 if col[1] > 0.2]\n",
    "selected_features2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Trains Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Demonstration of functions (completely same as those in libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "def predict1(test_games, lm, selected_features, choice):\n",
    "    \"\"\" takes test_games and model to output predictions (of whether a player is a votegetter) as a list and observations as a Series \"\"\"\n",
    "    \n",
    "    prediction = list()\n",
    "    \n",
    "    testdata_y = pd.DataFrame()\n",
    "    \n",
    "    for file in test_games:\n",
    "        \n",
    "        # Open test game file\n",
    "        df = pd.read_csv(f'./Data/{choice}/{file}')\n",
    "        \n",
    "        # Initialise a list for this game\n",
    "        tmp = [0 for i in range(len(df))]\n",
    "        \n",
    "        # Make predictions for 3 players most likely to get votes\n",
    "        x_final = df[selected_features].replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "        y_pred = lm.predict(x_final)\n",
    "        \n",
    "        # prepares test data by replacing the votes with 1 (1 means True/votegetter)\n",
    "        df['Brownlow Votes'] = df['Brownlow Votes'].replace([1, 2, 3], 1)\n",
    "        testdata_y = pd.concat([testdata_y, df['Brownlow Votes']], axis=0)\n",
    "        \n",
    "        # records the top three scorers with 1 (denoting 'marked as True/votegetter')\n",
    "        enumerated = [(i, score) for i, score in enumerate(y_pred)]\n",
    "        enumerated.sort(key = lambda x:x[1], reverse = True)\n",
    "        \n",
    "        for i in range(3):\n",
    "            tmp[enumerated[i][0]] = 1\n",
    "        \n",
    "        # Can un-comment to observe what actual scores the linear regression is outputting  \n",
    "#         print(enumerated[0:3])\n",
    "#         print(enumerated[-3:])\n",
    "        \n",
    "        prediction.extend(tmp)\n",
    "        \n",
    "    return prediction, testdata_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "def predict2(test_games, lm, selected_features, choice):\n",
    "    \"\"\" takes test_games and model to output predictions as a list and observations as a Series \"\"\"\n",
    "    \n",
    "    prediction = list()\n",
    "    \n",
    "    testdata_y = pd.DataFrame()\n",
    "    \n",
    "    for file in test_games:\n",
    "        \n",
    "        # Open test game file\n",
    "        df = pd.read_csv(f'./Data/{choice}/{file}')\n",
    "        \n",
    "        # slice out just the votegetters\n",
    "        df = df[df['Brownlow Votes'] > 0]\n",
    "        \n",
    "        # initialises list\n",
    "        tmp = [0 for i in range(len(df))]\n",
    "        \n",
    "        # Make predictions\n",
    "        x_final = df[selected_features].replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "        y_pred = lm.predict(x_final)\n",
    "        \n",
    "        # Collect the actual observations\n",
    "        testdata_y = pd.concat([testdata_y, df['Brownlow Votes']], axis=0)\n",
    "        \n",
    "        # Find top 3 scoring players for the game and allocate 3, 2, 1 votes to their respective index on the tmp list\n",
    "        enumerated = [(i, score) for i, score in enumerate(y_pred)]\n",
    "        enumerated.sort(key = lambda x:x[1], reverse = True)\n",
    "        \n",
    "        tmp[enumerated[0][0]] = 3\n",
    "        tmp[enumerated[1][0]] = 2\n",
    "        tmp[enumerated[2][0]] = 1\n",
    "        \n",
    "        # Can un-comment to observe what actual scores the linear regression is outputting \n",
    "#         print(enumerated[0:3])\n",
    "#         print(enumerated[-3:])\n",
    "        \n",
    "        prediction.extend(tmp)\n",
    "    \n",
    "    testdata_y.index = range(0, len(testdata_y))\n",
    "    \n",
    "    return prediction, testdata_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1(predictions, testdata_y, nchoice):\n",
    "    \"\"\" Calculates the tp/tn for no votes, have vote. Polymorphic as to how many choices there are \"\"\"\n",
    "    \n",
    "    # instantiate tally\n",
    "    result1 = list() # tp/tn/tp/fp calculated with respect to predictions (i.e. predicted 1, obs 0 => contribute to fp 1)\n",
    "    result2 = list() # tp/tn/tp/fp calculated with respect to observations (i.e. predicted 1, obs 0 => contribute to fp 0)\n",
    "    \n",
    "    # Initialise the result1 and result2 tallys based on nchoice\n",
    "    for i in range(nchoice):\n",
    "        tmp1 = [0 for j in range(nchoice)]\n",
    "        tmp2 = [0 for j in range(nchoice)]\n",
    "        result1.append(tmp1)\n",
    "        result2.append(tmp2)\n",
    "        \n",
    "    # Run through the predictions and add to tally according to whether it is tp/tn/fp/fn\n",
    "    for i in range(len(predictions)):\n",
    "        result1[predictions[i]][int(testdata_y.iloc[i][0])] += 1\n",
    "        result2[int(testdata_y.iloc[i][0])][predictions[i]] += 1\n",
    "    \n",
    "     # Find the sum of each row and then take percentage based on it (because we are taking tp/fp/tn/fn with respect to either predictions or observations rather than total)\n",
    "    for i in range(nchoice):\n",
    "        \n",
    "        sum_row1 = sum(result1[i])\n",
    "        sum_row2 = sum(result2[i])\n",
    "        \n",
    "        for j in range(nchoice):\n",
    "            result1[i][j] = result1[i][j]/sum_row1\n",
    "            result2[i][j] = result2[i][j]/sum_row2\n",
    "            \n",
    "    return result1, result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test2(predictions, testdata_y, nchoice):\n",
    "    \"\"\" Same as above except special adjustment for 1 vote, 2 votes 3 votes\"\"\"\n",
    "    \n",
    "    result1 = list()\n",
    "    result2 = list()\n",
    "    \n",
    "    for i in range(nchoice):\n",
    "        tmp1 = [0 for j in range(nchoice)]\n",
    "        tmp2 = [0 for j in range(nchoice)]\n",
    "        result1.append(tmp1)\n",
    "        result2.append(tmp2)\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        result1[predictions[i]-1][int(testdata_y.iloc[i][0])-1] += 1 # the use of -1 is a special adjustment\n",
    "        result2[int(testdata_y.iloc[i][0])-1][predictions[i]-1] += 1\n",
    "    \n",
    "    for i in range(nchoice):\n",
    "        \n",
    "        sum_row1 = sum(result1[i])\n",
    "        sum_row2 = sum(result2[i])\n",
    "        \n",
    "        for j in range(nchoice):\n",
    "            result1[i][j] = result1[i][j]/sum_row1\n",
    "            result2[i][j] = result2[i][j]/sum_row2\n",
    "            \n",
    "    return result1, result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also avaliable is the predict1_mass, predict2_mass, test1_mass and test2_mass function used in the scripts - not used in Proof of Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "def predict1_mass(test_games, lm, selected_features, choice):\n",
    "    \"\"\" takes test_games and model to output predictions (of whether a player is a votegetter) as a list and observations as a Series \"\"\"\n",
    "    \n",
    "    prediction = list()\n",
    "    \n",
    "    testdata_y = pd.DataFrame()\n",
    "    \n",
    "    for file in test_games:\n",
    "        \n",
    "        # Open test game file\n",
    "        df = pd.read_csv(f'./Data/{choice}/{file}')\n",
    "        \n",
    "        # Initialise a list for this game\n",
    "        tmp = [0 for i in range(len(df))]\n",
    "        \n",
    "        # Make predictions for 3 players most likely to get votes\n",
    "        x_final = df[selected_features].replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "        y_pred = lm.predict(x_final)\n",
    "        \n",
    "        # prepares test data by replacing the votes with 1 (1 means True/votegetter)\n",
    "        df['Brownlow Votes'] = df['Brownlow Votes'].replace([1, 2, 3], 1)\n",
    "        testdata_y = pd.concat([testdata_y, df['Brownlow Votes']], axis=0)\n",
    "        \n",
    "        # records the top three scorers with 1 (denoting 'marked as True/votegetter')\n",
    "        enumerated = [(i, score) for i, score in enumerate(y_pred)]\n",
    "        enumerated.sort(key = lambda x:x[1], reverse = True)\n",
    "        \n",
    "        for i in range(3):\n",
    "            tmp[enumerated[i][0]] = 1\n",
    "        \n",
    "        # Can un-comment to observe what actual scores the linear regression is outputting  \n",
    "#         print(enumerated[0:3])\n",
    "#         print(enumerated[-3:])\n",
    "        \n",
    "        prediction.extend(tmp)\n",
    "        \n",
    "    out = pd.DataFrame({'predictions': prediction, 'observations': list(testdata_y[testdata_y.columns[0]])})\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "def predict2_mass(test_games, lm, selected_features, choice):\n",
    "    \"\"\" takes test_games and model to output predictions as a list and observations as a Series \"\"\"\n",
    "    \n",
    "    prediction = list()\n",
    "    \n",
    "    testdata_y = pd.DataFrame()\n",
    "    \n",
    "    for file in test_games:\n",
    "        \n",
    "        # Open test game file\n",
    "        df = pd.read_csv(f'./Data/{choice}/{file}')\n",
    "        \n",
    "        # slice out just the votegetters\n",
    "        df = df[df['Brownlow Votes'] > 0]\n",
    "        \n",
    "        # initialises list\n",
    "        tmp = [0 for i in range(len(df))]\n",
    "        \n",
    "        # Make predictions\n",
    "        x_final = df[selected_features].replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "        y_pred = lm.predict(x_final)\n",
    "        \n",
    "        # Collect the actual observations\n",
    "        testdata_y = pd.concat([testdata_y, df['Brownlow Votes']], axis=0)\n",
    "        \n",
    "        # Find top 3 scoring players for the game and allocate 3, 2, 1 votes to their respective index on the tmp list\n",
    "        enumerated = [(i, score) for i, score in enumerate(y_pred)]\n",
    "        enumerated.sort(key = lambda x:x[1], reverse = True)\n",
    "        \n",
    "        tmp[enumerated[0][0]] = 3\n",
    "        tmp[enumerated[1][0]] = 2\n",
    "        tmp[enumerated[2][0]] = 1\n",
    "        \n",
    "        # Can un-comment to observe what actual scores the linear regression is outputting \n",
    "#         print(enumerated[0:3])\n",
    "#         print(enumerated[-3:])\n",
    "        \n",
    "        prediction.extend(tmp)\n",
    "    \n",
    "    testdata_y.index = range(0, len(testdata_y))\n",
    "    \n",
    "    out = pd.DataFrame({'predictions': prediction, 'observations': list(testdata_y[testdata_y.columns[0]])})\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "def test1_mass(out, adj_vote):\n",
    "    \"\"\" Helper function for returning tp/tn for mass testing for step 1 (more efficient as does not collect other stats)\"\"\"\n",
    "    \n",
    "    tp0 = len(out[(out['predictions'] == out['observations'].astype(int)) & (out['predictions'] == 0)])/len(out[(out['predictions'] == 0)])\n",
    "    tp1 = len(out[(out['predictions'] == out['observations'].astype(int)) & (out['predictions'] == 1)])/len(out[(out['predictions'] == adj_vote)])\n",
    "    \n",
    "    return (tp0, tp1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "def test2_mass(out):\n",
    "    \"\"\" Helper function for returning tp/tn for mass testing for step 2 (more efficient as does not collect other stats)\"\"\"\n",
    "    \n",
    "    tp1 = len(out[(out['predictions'] == out['observations'].astype(int)) & (out['predictions'] == 1)])/len(out[(out['predictions'] == 1)])\n",
    "    tp2 = len(out[(out['predictions'] == out['observations'].astype(int)) & (out['predictions'] == 2)])/len(out[(out['predictions'] == 2)])\n",
    "    tp3 = len(out[(out['predictions'] == out['observations'].astype(int)) & (out['predictions'] == 3)])/len(out[(out['predictions'] == 3)])\n",
    "    \n",
    "    return (tp1, tp2, tp3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Micro Rule of Feature Selection 1: \n",
    "\n",
    "*All cols that passed FS_val selected*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains LR model for step 1\n",
    "traindataf_x_1 = first_lr_data[selected_features1]\n",
    "traindataf_x_1.index = range(0,len(first_lr_data))\n",
    "traindataf_y_1 = first_lr_data['Brownlow Votes']\n",
    "traindataf_y_1.index = range(0,len(first_lr_data))\n",
    "\n",
    "lm_f_1 = linear_model.LinearRegression()\n",
    "traindataf_x_1 = traindataf_x_1.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "modelf_1 = lm_f_1.fit(traindataf_x_1, traindataf_y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and observations for step 1\n",
    "predictionsf_1, testdataf_y_1 = predict1(test_games, lm_f_1, selected_features1, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get True Positive/True Negative results for step 1\n",
    "resultf1_1, resultf2_1 = test1(predictionsf_1, testdataf_y_1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9702843753328363, 0.029715624667163702],\n",
       " [0.40611353711790393, 0.5938864628820961]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP/TN based on what was predicted for step 1\n",
    "resultf1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9702843753328363, 0.029715624667163702],\n",
       " [0.40611353711790393, 0.5938864628820961]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP/TN based on what was observed for step 1\n",
    "resultf2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9702843753328363, 0.5938864628820961)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only the True Positive Values for step 1\n",
    "return_tp(resultf1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains LR model for step 2\n",
    "traindatas_x_1 = second_lr_data[selected_features2]\n",
    "traindatas_x_1.index = range(0,len(second_lr_data))\n",
    "traindatas_y_1 = second_lr_data['Brownlow Votes']\n",
    "traindatas_y_1.index = range(0,len(second_lr_data))\n",
    "\n",
    "lm_s_1 = linear_model.LinearRegression()\n",
    "traindatas_x_1 = traindatas_x_1.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "models_1 = lm_s_1.fit(traindatas_x_1, traindatas_y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and observations for step 2\n",
    "predictionss_1, testdatas_y_1 = predict2(test_games, lm_s_1, selected_features2, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get True Positive/True Negative results for step 2\n",
    "results1_1, results2_1 = test2(predictionss_1, testdatas_y_1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.42358078602620086, 0.3406113537117904, 0.23580786026200873],\n",
       " [0.31877729257641924, 0.34934497816593885, 0.3318777292576419],\n",
       " [0.2576419213973799, 0.31004366812227074, 0.43231441048034935]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP/TN based on what was predicted for step 2\n",
    "results1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.42358078602620086, 0.31877729257641924, 0.2576419213973799],\n",
       " [0.3406113537117904, 0.34934497816593885, 0.31004366812227074],\n",
       " [0.23580786026200873, 0.3318777292576419, 0.43231441048034935]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP/TN based on what was observed for step 2\n",
    "results2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.42358078602620086, 0.34934497816593885, 0.43231441048034935)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only the True Positive Values for step 2\n",
    "return_tp(results1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Micro Rule of Feature Selection 2\n",
    "\n",
    "*-For those with dependency/triangle relationships (i.e. A=Disposals/B=Kicks/C=Handballs), if A comes first then B, C excluded. If B or C comes first then A excluded*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Goals BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Score Involvements BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selects feature according to micro FS_Rule for step-1\n",
    "selected_features1_2 = feature_selection2(selected_features1, 2, False)\n",
    "selected_features1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Score Involvements BTN']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selects feature according to micro FS_Rule for step-2\n",
    "selected_features2_2 = feature_selection2(selected_features2, 2, False)\n",
    "selected_features2_2\n",
    "#All other operations hereonin same as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataf_x_2 = first_lr_data[selected_features1_2]\n",
    "traindataf_x_2.index = range(0,len(first_lr_data))\n",
    "traindataf_y_2 = first_lr_data['Brownlow Votes']\n",
    "traindataf_y_2.index = range(0,len(first_lr_data))\n",
    "\n",
    "lm_f_2 = linear_model.LinearRegression()\n",
    "traindataf_x_2 = traindataf_x_2.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "modelf_2 = lm_f_2.fit(traindataf_x_2, traindataf_y_2)\n",
    "\n",
    "predictionsf_2, testdataf_y_2 = predict1(test_games, lm_f_2, selected_features1_2, choice)\n",
    "\n",
    "resultf1_2, resultf2_2 = test1(predictionsf_2, testdataf_y_2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9697518372563638, 0.03024816274363617],\n",
       " [0.413391557496361, 0.586608442503639]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultf1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9697518372563638, 0.03024816274363617],\n",
       " [0.413391557496361, 0.586608442503639]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultf2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9697518372563638, 0.586608442503639)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_tp(resultf1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatas_x_2 = second_lr_data[selected_features2_2]\n",
    "traindatas_x_2.index = range(0,len(second_lr_data))\n",
    "traindatas_y_2 = second_lr_data['Brownlow Votes']\n",
    "traindatas_y_2.index = range(0,len(second_lr_data))\n",
    "\n",
    "lm_s_2 = linear_model.LinearRegression()\n",
    "traindatas_x_2 = traindatas_x_2.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "models_2 = lm_s_2.fit(traindatas_x_2, traindatas_y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionss_2, testdatas_y_2 = predict2(test_games, lm_s_2, selected_features2_2, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1_2, results2_2 = test2(predictionss_2, testdatas_y_2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.43231441048034935, 0.32751091703056767, 0.24017467248908297],\n",
       " [0.31877729257641924, 0.38427947598253276, 0.29694323144104806],\n",
       " [0.24890829694323144, 0.28820960698689957, 0.462882096069869]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.43231441048034935, 0.31877729257641924, 0.24890829694323144],\n",
       " [0.32751091703056767, 0.38427947598253276, 0.28820960698689957],\n",
       " [0.24017467248908297, 0.29694323144104806, 0.462882096069869]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43231441048034935, 0.38427947598253276, 0.462882096069869)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_tp(results1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Micro Rule of Feature Selection 3: \n",
    "\n",
    "*All cols that passed FS_val selected but abandon all 'summary' cols such as Disposal/Tackles/Marks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Goals BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Centre Clearances BTN',\n",
       " 'Stoppage Clearances BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Behind Assists BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features1_3 = feature_selection2(selected_features1, 3, False)\n",
    "selected_features1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Behind Assists BTN']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features2_3 = feature_selection2(selected_features2, 3, False)\n",
    "selected_features2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataf_x_3 = first_lr_data[selected_features1_3]\n",
    "traindataf_x_3.index = range(0,len(first_lr_data))\n",
    "traindataf_y_3 = first_lr_data['Brownlow Votes']\n",
    "traindataf_y_3.index = range(0,len(first_lr_data))\n",
    "\n",
    "lm_f_3 = linear_model.LinearRegression()\n",
    "traindataf_x_3 = traindataf_x_3.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "modelf_3 = lm_f_3.fit(traindataf_x_3, traindataf_y_3)\n",
    "\n",
    "predictionsf_3, testdataf_y_3 = predict1(test_games, lm_f_3, selected_features1_3, choice)\n",
    "\n",
    "resultf1_3, resultf2_3 = test1(predictionsf_3, testdataf_y_3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9695388220257748, 0.030461177974225158],\n",
       " [0.4163027656477438, 0.5836972343522562]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultf1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9695388220257748, 0.030461177974225158],\n",
       " [0.4163027656477438, 0.5836972343522562]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultf2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9695388220257748, 0.5836972343522562)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_tp(resultf1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatas_x_3 = second_lr_data[selected_features2_3]\n",
    "traindatas_x_3.index = range(0,len(second_lr_data))\n",
    "traindatas_y_3 = second_lr_data['Brownlow Votes']\n",
    "traindatas_y_3.index = range(0,len(second_lr_data))\n",
    "\n",
    "lm_s_3 = linear_model.LinearRegression()\n",
    "traindatas_x_3 = traindatas_x_3.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "models_3 = lm_s_3.fit(traindatas_x_3, traindatas_y_3)\n",
    "\n",
    "predictionss_3, testdatas_y_3 = predict2(test_games, lm_s_3, selected_features2_3, choice)\n",
    "\n",
    "results1_3, results2_3 = test2(predictionss_3, testdatas_y_3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.4148471615720524, 0.33624454148471616, 0.24890829694323144],\n",
       " [0.3624454148471616, 0.3537117903930131, 0.2838427947598253],\n",
       " [0.22270742358078602, 0.31004366812227074, 0.4672489082969432]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.4148471615720524, 0.3624454148471616, 0.22270742358078602],\n",
       " [0.33624454148471616, 0.3537117903930131, 0.31004366812227074],\n",
       " [0.24890829694323144, 0.2838427947598253, 0.4672489082969432]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4148471615720524, 0.3537117903930131, 0.4672489082969432)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_tp(results1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Micro Rule of Feature Selection 4: \n",
    "\n",
    "*Exclude Disposals, otherwise as per rule 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Goals BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Score Involvements BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features1_4 = feature_selection2(selected_features1, 4, False)\n",
    "selected_features1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Goals BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Score Involvements BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features2_4 = feature_selection2(selected_features1, 4, False)\n",
    "selected_features2_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataf_x_4 = first_lr_data[selected_features1_4]\n",
    "traindataf_x_4.index = range(0,len(first_lr_data))\n",
    "traindataf_y_4 = first_lr_data['Brownlow Votes']\n",
    "traindataf_y_4.index = range(0,len(first_lr_data))\n",
    "\n",
    "lm_f_4 = linear_model.LinearRegression()\n",
    "traindataf_x_4 = traindataf_x_4.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "modelf_4 = lm_f_4.fit(traindataf_x_4, traindataf_y_4)\n",
    "\n",
    "predictionsf_4, testdataf_y_4 = predict1(test_games, lm_f_4, selected_features1_4, choice)\n",
    "\n",
    "resultf1_4, resultf2_4 = test1(predictionsf_4, testdataf_y_4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9697518372563638, 0.03024816274363617],\n",
       " [0.413391557496361, 0.586608442503639]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultf1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9697518372563638, 0.03024816274363617],\n",
       " [0.413391557496361, 0.586608442503639]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultf2_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9697518372563638, 0.586608442503639)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_tp(resultf1_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatas_x_4 = second_lr_data[selected_features2_4]\n",
    "traindatas_x_4.index = range(0,len(second_lr_data))\n",
    "traindatas_y_4 = second_lr_data['Brownlow Votes']\n",
    "traindatas_y_4.index = range(0,len(second_lr_data))\n",
    "\n",
    "lm_s_4 = linear_model.LinearRegression()\n",
    "traindatas_x_4 = traindatas_x_4.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "models_4 = lm_s_4.fit(traindatas_x_4, traindatas_y_4)\n",
    "\n",
    "predictionss_4, testdatas_y_4 = predict2(test_games, lm_s_4, selected_features2_4, choice)\n",
    "\n",
    "results1_4, results2_4 = test2(predictionss_4, testdatas_y_4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5545851528384279, 0.3318777292576419, 0.11353711790393013],\n",
       " [0.25327510917030566, 0.37117903930131, 0.37554585152838427],\n",
       " [0.19213973799126638, 0.29694323144104806, 0.5109170305676856]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5545851528384279, 0.25327510917030566, 0.19213973799126638],\n",
       " [0.3318777292576419, 0.37117903930131, 0.29694323144104806],\n",
       " [0.11353711790393013, 0.37554585152838427, 0.5109170305676856]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5545851528384279, 0.37117903930131, 0.5109170305676856)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_tp(results1_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Summary Observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Demonstration of functions (completely same as those in libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "from collections import defaultdict as dd\n",
    "# import numpy as np\n",
    "\n",
    "def wholeseason(final_test_games, lm1, lm2, selected_features1, selected_features2, choice):\n",
    "    \"\"\" Helper function for running emperical test - returns tuple of leaderboard of players for the season (with votes) \"\"\"\n",
    "    \n",
    "    players = dd(int)\n",
    "    \n",
    "    for file in final_test_games:\n",
    "        \n",
    "        # Open each final test season's game\n",
    "        df = pd.read_csv(f'./Data/{choice}/{file}')\n",
    "        \n",
    "        # Run predictions for step 1\n",
    "        x_final = df[selected_features1].replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "        y_pred = lm1.predict(x_final)\n",
    "        \n",
    "        # find top 3 scoring players of the game for step 1 - the predicted votegetters\n",
    "        enumerated = [(i, score) for i, score in enumerate(y_pred)]\n",
    "        enumerated.sort(key = lambda x:x[1], reverse = True)\n",
    "        \n",
    "        # Find index for the predicted votegetters and make relevant dataframe\n",
    "        secondround = [x[0] for x in enumerated[0:3]]\n",
    "        \n",
    "        df2 = df.iloc[secondround]\n",
    "        df2.index = list(range(3))\n",
    "        \n",
    "        # Run predictions for step 2\n",
    "        y_pred2 = lm2.predict(df2[selected_features2])\n",
    "        \n",
    "        # Rank the top 3 players of the game from highest score to lowest\n",
    "        enumerated2 = [(i, score) for i, score in enumerate(y_pred2)]\n",
    "        enumerated2.sort(key = lambda x:x[1], reverse = True)\n",
    "        \n",
    "         # Find their (top 3 players) names and insert them into the tally by adding 3 votes, 2 votes and 1 vote respectively\n",
    "        for j in range(3):\n",
    "            index = secondround[enumerated2[j][0]]\n",
    "            players[df.loc[index]['Player']] += (3-j)\n",
    "    \n",
    "    # Sort the leaderboard so top pollers are ranked first\n",
    "    leaderboard = sorted(list(players.items()), reverse = True, key = lambda x:x[1])\n",
    "    \n",
    "    return leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Emperical Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard1 = wholeseason(final_test_games, lm_f_1, lm_s_1, selected_features1, selected_features2, choice)\n",
    "leaderboard2 = wholeseason(final_test_games, lm_f_2, lm_s_2, selected_features1_2, selected_features2_2, choice)\n",
    "leaderboard3 = wholeseason(final_test_games, lm_f_3, lm_s_3, selected_features1_3, selected_features2_3, choice)\n",
    "leaderboard4 = wholeseason(final_test_games, lm_f_4, lm_s_4, selected_features1_4, selected_features2_4, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Christian Petracca', 32),\n",
       " ('Oliver Wines', 31),\n",
       " ('Clayton Oliver', 27),\n",
       " ('Darcy Parish', 27),\n",
       " ('Jarryd Lyons', 26),\n",
       " ('Jack Steele', 26),\n",
       " ('Marcus Bontempelli', 24),\n",
       " ('Tom Mitchell', 21),\n",
       " ('Jackson Macrae', 21),\n",
       " ('David Mundy', 21),\n",
       " ('Sam Walsh', 20),\n",
       " ('Luke Parker', 20),\n",
       " ('Jake Stringer', 20),\n",
       " ('Cameron Guthrie', 18),\n",
       " ('Travis Boak', 18)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard1[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Clayton Oliver', 30),\n",
       " ('Christian Petracca', 29),\n",
       " ('Oliver Wines', 27),\n",
       " ('Jack Steele', 27),\n",
       " ('Jarryd Lyons', 26),\n",
       " ('Darcy Parish', 26),\n",
       " ('Sam Walsh', 24),\n",
       " ('Marcus Bontempelli', 23),\n",
       " ('Thomas Liberatore', 21),\n",
       " ('Travis Boak', 21),\n",
       " ('David Mundy', 21),\n",
       " ('Cameron Guthrie', 19),\n",
       " ('Jackson Macrae', 19),\n",
       " ('Tom Mitchell', 18),\n",
       " ('Rory Laird', 18)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard2[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Christian Petracca', 34),\n",
       " ('Oliver Wines', 31),\n",
       " ('Clayton Oliver', 28),\n",
       " ('Darcy Parish', 28),\n",
       " ('Jack Steele', 26),\n",
       " ('Jarryd Lyons', 25),\n",
       " ('Sam Walsh', 22),\n",
       " ('Tom Mitchell', 21),\n",
       " ('Jackson Macrae', 21),\n",
       " ('Marcus Bontempelli', 21),\n",
       " ('Cameron Guthrie', 20),\n",
       " ('David Mundy', 20),\n",
       " ('Rory Laird', 19),\n",
       " ('Callum Mills', 18),\n",
       " ('Thomas Liberatore', 18)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard3[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Oliver Wines', 33),\n",
       " ('Jack Steele', 32),\n",
       " ('Darcy Parish', 30),\n",
       " ('Jarryd Lyons', 29),\n",
       " ('Clayton Oliver', 29),\n",
       " ('Christian Petracca', 27),\n",
       " ('Tom Mitchell', 26),\n",
       " ('Touk Miller', 24),\n",
       " ('Jackson Macrae', 24),\n",
       " ('Marcus Bontempelli', 23),\n",
       " ('Rory Laird', 22),\n",
       " ('Cameron Guthrie', 21),\n",
       " ('Sam Walsh', 21),\n",
       " ('Travis Boak', 20),\n",
       " ('Taylor Adams', 18)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard4[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Predictor's r scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24076122459350024\n",
      "0.05801737930048212\n",
      "0.23898619444693103\n",
      "0.057988964505007116\n",
      "0.2391997414305683\n",
      "0.050570156027257\n",
      "0.23898619444693103\n",
      "0.1330176528809971\n"
     ]
    }
   ],
   "source": [
    "print(lm_f_1.score(traindataf_x_1, traindataf_y_1))\n",
    "print(lm_s_1.score(traindatas_x_1, traindatas_y_1))\n",
    "print(lm_f_2.score(traindataf_x_2, traindataf_y_2))\n",
    "print(lm_s_2.score(traindatas_x_2, traindatas_y_2))\n",
    "print(lm_f_3.score(traindataf_x_3, traindataf_y_3))\n",
    "print(lm_s_3.score(traindatas_x_3, traindatas_y_3))\n",
    "print(lm_f_4.score(traindataf_x_4, traindataf_y_4))\n",
    "print(lm_s_4.score(traindatas_x_4, traindatas_y_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: A few improvements could be made on this notebook: ##\n",
    "\n",
    "*1. A good way to get real tp1, tp2, tp3 stats may be to use the actual predicted indexes from predict1 in predict2. Current model only tests lm2's ability to rank correctly given the top 3 players, and assumes it has similar capabilities for any three players*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
