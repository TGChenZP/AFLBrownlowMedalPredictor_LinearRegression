{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Concept 5. Double Linear Regression with Bootstrap using Normalised Data/Both Teams #\n",
    "## For Brownlow Predictor Project ##\n",
    "\n",
    "Trains up 1 models using Normalised Data/Both Team Columns Only (FS_Val = 0.2 and Includes Winloss)\n",
    "\n",
    "Experiments with using PCA for feature selection\n",
    "\n",
    "\n",
    "**Author: `Lang (Ron) Chen` 2021.12-2022.1**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from BrownlowPredictorPCA.predict import predict\n",
    "from BrownlowPredictorTools.test import test\n",
    "from BrownlowPredictorTools.return_tp import return_tp\n",
    "from BrownlowPredictorPCA.wholeseason import wholeseason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 'NormalisedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = os.listdir(f'./Data/{choice}')[1:]\n",
    "# Remove the first file (an ipynb checkpoint file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets list of emperical test games (full 2021 season)\n",
    "final_test_games = [file for file in filelist if '2021' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathers full games list (except 2021) and performs a single Train-Test Split (note different from previous KFold)\n",
    "test_train_games = [file for file in filelist if '2021' not in file]\n",
    "train_games, test_games = train_test_split(test_train_games, train_size = 0.8, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pre-prepared sample data of trained data only \n",
    "# (the same rows as if we used concatenated all the data from the train_games list)\n",
    "train_data = pd.read_csv('Train_Data (N).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialises PCA\n",
    "pca = PCA(n_components = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in train_data.columns if ('BTN' in col or 'Winloss' in col)]\n",
    "\n",
    "corr = dict()\n",
    "for col in cols:\n",
    "    corr[col] = train_data[[col, 'Brownlow Votes']].corr(method = 'pearson').loc[col]['Brownlow Votes']\n",
    "corr\n",
    "\n",
    "corr = list(corr.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Disposals BTN',\n",
       " 'Goals BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Centre Clearances BTN',\n",
       " 'Stoppage Clearances BTN',\n",
       " 'Score Involvements BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Behind Assists BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = [col[0] for col in corr if col[1] > 0.2]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Trains Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Demonstration of functions (completely same as those in libraries)\n",
    "\n",
    "Will only comment parts that are different (PCA specific). Can see PoC1 for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "def predict(test_games, lm, selected_features, choice, pca):\n",
    "    \"\"\" takes test_games and model and pca object to output predictions as a list and observations as a Series \"\"\"\n",
    "    \n",
    "    prediction = list()\n",
    "    \n",
    "    testdata_y = pd.DataFrame()\n",
    "    \n",
    "    for file in test_games:\n",
    "        \n",
    "        df = pd.read_csv(f'./Data/{choice}/{file}')\n",
    "        \n",
    "        tmp = [0 for i in range(len(df))]\n",
    "        \n",
    "        x_final = df[selected_features].replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "        y_pred = lm.predict(pca.transform(x_final)) # must transform the data using same pca object as training object\n",
    "        \n",
    "        testdata_y = pd.concat([testdata_y, df['Brownlow Votes']], axis=0)\n",
    "        \n",
    "        enumerated = [(i, score) for i, score in enumerate(y_pred)]\n",
    "        enumerated.sort(key = lambda x:x[1], reverse = True)\n",
    "        \n",
    "        tmp[enumerated[0][0]] = 3\n",
    "        tmp[enumerated[1][0]] = 2\n",
    "        tmp[enumerated[2][0]] = 1\n",
    "#         print(enumerated[0:3])\n",
    "#         print(enumerated[-3:])\n",
    "        \n",
    "        prediction = prediction + tmp\n",
    "        \n",
    "    return prediction, testdata_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also avaliable is the PCA specific predict_mass function used in the scripts - not used in Proof of Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mass(test_games, lm, selected_features, choice, pca):\n",
    "    \"\"\" takes test_games and model and pca object to output predictions as a list and observations as a Series \"\"\"\n",
    "    \n",
    "    prediction = list()\n",
    "    \n",
    "    testdata_y = pd.DataFrame()\n",
    "    \n",
    "    for file in test_games:\n",
    "        \n",
    "        df = pd.read_csv(f'./Data/{choice}/{file}')\n",
    "        \n",
    "        tmp = [0 for i in range(len(df))]\n",
    "        \n",
    "        x_final = df[selected_features].replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "        y_pred = lm.predict(pca.transform(x_final)) # must transform the data using same pca object as training object\n",
    "        \n",
    "        testdata_y = pd.concat([testdata_y, df['Brownlow Votes']], axis=0)\n",
    "        \n",
    "        enumerated = [(i, score) for i, score in enumerate(y_pred)]\n",
    "        enumerated.sort(key = lambda x:x[1], reverse = True)\n",
    "        \n",
    "        tmp[enumerated[0][0]] = 3\n",
    "        tmp[enumerated[1][0]] = 2\n",
    "        tmp[enumerated[2][0]] = 1\n",
    "#         print(enumerated[0:3])\n",
    "#         print(enumerated[-3:])\n",
    "        \n",
    "        prediction = prediction + tmp\n",
    "\n",
    "    out = pd.DataFrame({'predictions': prediction, 'observations': list(testdata_y[testdata_y.columns[0]])})\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Regular model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains LR model\n",
    "traindata_x_1 = train_data[selected_features]\n",
    "traindata_x_1 = traindata_x_1.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "traindata_x_1.index = range(0,len(traindata_x_1))\n",
    "\n",
    "principalComponents = pca.fit_transform(traindata_x_1) # fits pca model and transforms using it\n",
    "\n",
    "traindata_y_1 = train_data['Brownlow Votes']\n",
    "traindata_y_1.index = range(0,len(traindata_y_1))\n",
    "\n",
    "lm_1 = linear_model.LinearRegression()\n",
    "model_1 = lm_1.fit(principalComponents, traindata_y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49335605, 0.13844796, 0.12263638, 0.06489825, 0.03992478])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints pca explained variance\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and observations\n",
    "predictions_1, testdata_y_1 = predict(test_games, lm_1, selected_features, choice, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get True Positive/True Negative results\n",
    "result1_1, result2_1 = test(predictions_1, testdata_y_1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.967195654489296,\n",
       "  0.014272020449462136,\n",
       "  0.012141868143572265,\n",
       "  0.006390456917669613],\n",
       " [0.62882096069869,\n",
       "  0.13973799126637554,\n",
       "  0.1222707423580786,\n",
       "  0.1091703056768559],\n",
       " [0.5021834061135371,\n",
       "  0.13973799126637554,\n",
       "  0.1615720524017467,\n",
       "  0.1965065502183406],\n",
       " [0.21397379912663755,\n",
       "  0.13537117903930132,\n",
       "  0.2183406113537118,\n",
       "  0.43231441048034935]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP/TN based on what was predicted\n",
    "result1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.967195654489296,\n",
       "  0.015337096602407072,\n",
       "  0.012248375758866758,\n",
       "  0.005218873149430184],\n",
       " [0.5851528384279476,\n",
       "  0.13973799126637554,\n",
       "  0.13973799126637554,\n",
       "  0.13537117903930132],\n",
       " [0.4978165938864629,\n",
       "  0.1222707423580786,\n",
       "  0.1615720524017467,\n",
       "  0.2183406113537118],\n",
       " [0.26200873362445415,\n",
       "  0.1091703056768559,\n",
       "  0.1965065502183406,\n",
       "  0.43231441048034935]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP/TN based on what was observed\n",
    "result2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.967195654489296,\n",
       " 0.13973799126637554,\n",
       " 0.1615720524017467,\n",
       " 0.43231441048034935)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only the True Positive Values\n",
    "return_tp(result1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Summary Observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Demonstration of functions (completely same as those in libraries)\n",
    "\n",
    "Will only comment parts that are different. Can see PoC1 for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "from collections import defaultdict as dd\n",
    "# import numpy as np\n",
    "\n",
    "def wholeseason(final_test_games, lm, selected_features, choice, pca):\n",
    "    \"\"\" Helper function for running emperical test - returns tuple of leaderboard of players for the season (with votes) \"\"\"\n",
    "    \n",
    "    players = dd(int)\n",
    "    \n",
    "    for file in final_test_games:\n",
    "        \n",
    "        df = pd.read_csv(f'./Data/{choice}/{file}')\n",
    "        \n",
    "        x_final = df[selected_features].replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "        y_pred = lm.predict(pca.transform(x_final)) # must transform the data using same pca object as training object\n",
    "        \n",
    "        enumerated = [(i, score) for i, score in enumerate(y_pred)]\n",
    "        enumerated.sort(key = lambda x:x[1], reverse = True)\n",
    "        \n",
    "        for j in range(3):\n",
    "            players[df.loc[enumerated[j][0]]['Player']] += (3-j)\n",
    "    \n",
    "    leaderboard = sorted(list(players.items()), reverse = True, key = lambda x:x[1])\n",
    "    \n",
    "    return leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Emperical Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard1 = wholeseason(final_test_games, lm_1, selected_features, choice, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Clayton Oliver', 40),\n",
       " ('Oliver Wines', 37),\n",
       " ('Christian Petracca', 34),\n",
       " ('Jack Steele', 34),\n",
       " ('Darcy Parish', 31),\n",
       " ('Rory Laird', 29),\n",
       " ('Touk Miller', 28),\n",
       " ('Travis Boak', 27),\n",
       " ('Jackson Macrae', 26),\n",
       " ('Marcus Bontempelli', 26),\n",
       " ('Cameron Guthrie', 24),\n",
       " ('Jarryd Lyons', 24),\n",
       " ('Tom Mitchell', 24),\n",
       " ('Sam Walsh', 24),\n",
       " ('Callum Mills', 21)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard1[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Predictor's r scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21231256572941914\n"
     ]
    }
   ],
   "source": [
    "print(lm_1.score(principalComponents, traindata_y_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
