{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2. LR-N-BT-0.2-1 ##\n",
    "\n",
    "Trains model 2 based on:\n",
    "\n",
    "- Regular Linear Regression\n",
    "- Normalised Data \n",
    "- Both Teams data\n",
    "- FS_Val 0.2\n",
    "- FS_Rule 1\n",
    "\n",
    "**Author: `Lang (Ron) Chen` 2021.12-2022.1**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from BrownlowPredictorTools.predict import predict\n",
    "from BrownlowPredictorTools.test import test\n",
    "from BrownlowPredictorTools.return_tp import return_tp\n",
    "from BrownlowPredictorTools.wholeseason import wholeseason\n",
    "from BrownlowPredictorTools.feature_selection2 import feature_selection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 'NormalisedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = os.listdir(f'./Data/{choice}')\n",
    "filelist.sort()\n",
    "filelist = filelist[1:]\n",
    "# Remove the first file (an ipynb checkpoint file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we need to perform tests to evaluate this final model, still need to use do this\n",
    "\n",
    "# Gets list of emperical test games (full 2021 season)\n",
    "final_test_games = [file for file in filelist if '2021' in file]\n",
    "\n",
    "# Gathers full games list (except 2021) and performs a single Train-Test Split (note different from previous KFold)\n",
    "test_train_games = [file for file in filelist if '2021' not in file]\n",
    "train_games, test_games = train_test_split(test_train_games, train_size = 0.8, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pre-prepared sample data of trained data only \n",
    "# (the same rows as if we used concatenated all the data from the train_games list)\n",
    "train_data = pd.read_csv('./Models/TrainingData/M2_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Disposals BTN',\n",
       " 'Goals BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Centre Clearances BTN',\n",
       " 'Stoppage Clearances BTN',\n",
       " 'Score Involvements BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Behind Assists BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Columns of Both Teams Stats only\n",
    "cols = [col for col in train_data.columns if ('BTN' in col or 'Winloss' in col)]\n",
    "\n",
    "# Select Columns with correlation higher than 0.2 only\n",
    "corr = dict()\n",
    "for col in cols:\n",
    "    corr[col] = train_data[[col, 'Brownlow Votes']].corr(method = 'pearson').loc[col]['Brownlow Votes']\n",
    "\n",
    "\n",
    "corr = list(corr.items())\n",
    "\n",
    "selected_features = [col[0] for col in corr if col[1] > 0.2]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Trains Model using rule 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No need to run feature_selection2 because this utilises rule 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains LR model\n",
    "traindata_x = train_data[selected_features]\n",
    "traindata_x.index = range(0,len(traindata_x))\n",
    "traindata_y = train_data['Brownlow Votes']\n",
    "traindata_y.index = range(0,len(traindata_y))\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "traindata_x = traindata_x.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "model = lm.fit(traindata_x, traindata_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and observations\n",
    "predictions, testdata_y = predict(test_games, lm, selected_features, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get True Positive/True Negative results\n",
    "result1, result2 = test(predictions, testdata_y, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9697518372563638,\n",
       "  0.013845989988284162,\n",
       "  0.01107679199062733,\n",
       "  0.005325380764724678],\n",
       " [0.6331877729257642,\n",
       "  0.17467248908296942,\n",
       "  0.09170305676855896,\n",
       "  0.10043668122270742],\n",
       " [0.39737991266375544,\n",
       "  0.11790393013100436,\n",
       "  0.2183406113537118,\n",
       "  0.2663755458515284],\n",
       " [0.2096069868995633,\n",
       "  0.13973799126637554,\n",
       "  0.23580786026200873,\n",
       "  0.4148471615720524]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP/TN based on what was predicted\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9697518372563638,\n",
       "  0.015443604217701567,\n",
       "  0.009692192991798914,\n",
       "  0.00511236553413569],\n",
       " [0.5676855895196506,\n",
       "  0.17467248908296942,\n",
       "  0.11790393013100436,\n",
       "  0.13973799126637554],\n",
       " [0.45414847161572053,\n",
       "  0.09170305676855896,\n",
       "  0.2183406113537118,\n",
       "  0.23580786026200873],\n",
       " [0.2183406113537118,\n",
       "  0.10043668122270742,\n",
       "  0.2663755458515284,\n",
       "  0.4148471615720524]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP/TN based on what was observed\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9697518372563638,\n",
       " 0.17467248908296942,\n",
       " 0.2183406113537118,\n",
       " 0.4148471615720524)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only the True Positive Values\n",
    "return_tp(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Summary Observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Emperical Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the season 2021 data onto predictor and gets top players\n",
    "leaderboard = wholeseason(final_test_games, lm, selected_features, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Oliver Wines', 34),\n",
       " ('Jack Steele', 33),\n",
       " ('Christian Petracca', 30),\n",
       " ('Clayton Oliver', 28),\n",
       " ('Darcy Parish', 28),\n",
       " ('Jarryd Lyons', 27),\n",
       " ('Tom Mitchell', 27),\n",
       " ('Jackson Macrae', 27),\n",
       " ('Marcus Bontempelli', 26),\n",
       " ('Rory Laird', 23),\n",
       " ('Jake Stringer', 21),\n",
       " ('Cameron Guthrie', 20),\n",
       " ('Touk Miller', 20),\n",
       " ('Luke Parker', 20),\n",
       " ('Sam Walsh', 19)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Predictor's r scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23298806127226634\n"
     ]
    }
   ],
   "source": [
    "print(lm.score(traindata_x, traindata_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Picklising**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Models/M2.pickle', 'wb') as f:\n",
    "    pickle.dump([lm, selected_features, choice], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
