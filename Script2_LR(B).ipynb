{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script 2. Training and collecting statistics from Linear Regression Models with Bootstrapping #\n",
    "## For Brownlow Predictor Project ##\n",
    "\n",
    "Trains and collects statistics from 4000 different LR Models with Bootstrapping for Brownlow Predicting\n",
    "\n",
    "Different models arise from the permutations of choices one can make when training models. For this case they are:\n",
    "- [x] 5 Data Manipulation Types\n",
    "- [x] 4 Macro Rules of Feature Selection \n",
    "- [x] 4 Feature Selection Coefficient Cutoff Values \n",
    "- [x] 4 Micro Rules of Feature Selection\n",
    "- [x] 2 Whether to include Winloss in columns\n",
    "- [x] (5 Folds of Train-Test Split)\n",
    "\n",
    "\n",
    "**Author: `Lang (Ron) Chen` 2021.12-2022.1**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "from BrownlowPredictorTools.predict import predict_mass\n",
    "from BrownlowPredictorTools.test import test_mass\n",
    "from BrownlowPredictorTools.return_tp import return_tp\n",
    "from BrownlowPredictorTools.wholeseason import wholeseason\n",
    "from BrownlowPredictorTools.feature_selection2 import feature_selection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Central_Statistics = pd.read_csv('Central_Statistics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Using Loops to simulate permutations**\n",
    "\n",
    "*Makes clever use of f-strings to input and output the desired data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (52) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8h 47min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "choice = {'N': 'NormalisedData', 'S': 'StandardisedData', 'RS': 'RankStandardisedData', \n",
    "          'P': 'PercentageData', 'PN': 'PercentageNormalisedData'}\n",
    "\n",
    "for dt in ['N', 'S', 'RS', 'P', 'PN']: # 5 Data Manipulation Types\n",
    "    \n",
    "    filelist = os.listdir(f'./Data/{choice[dt]}')[1:]\n",
    "    \n",
    "    # Gets list of emperical test games (full 2021 season)\n",
    "    final_test_games = [file for file in filelist if '2021' in file]\n",
    "    \n",
    "    for use in ['BT', 'OT', 'BT_OT', 'BT+OT']:\n",
    "        \n",
    "        # BT: Both Teams\n",
    "        # OT: Own Team\n",
    "        # BT_OT: Both Teams data OR Own Team data (same stat cannot use both columns)\n",
    "        # BT+OT: Both Teams data AND Own Team data (free to use both columns for same stats)\n",
    "        \n",
    "        BT_OT = False # Variable to be used later in feature_selection2() function\n",
    "        if use == 'BT_OT':\n",
    "            BT_OT = True\n",
    "        \n",
    "        for FS_val in [0.2, 0.25, 0.3, 0.35]: # 4 Feature Selection Coefficient Cutoff Values: Above what level of \n",
    "            # pearsons correlation coeffcient does a column have to be in order to be selected as a feature \n",
    "            \n",
    "            for FS_rule in [1, 2, 3, 4]: # 4 Micro Rules of Feature Selection\n",
    "                \n",
    "                # 1: All cols that passed FS_val selected\n",
    "                # 2: For those with dependency/triangle relationships (i.e. A=Disposals/B=Kicks/C=Handballs), if A comes first then B, C excluded. If B or C comes first then A excluded\n",
    "                # 3: All cols that passed FS_val selected but abandon all 'summary' cols such as Disposal/Tackles/Marks\n",
    "                # 4: Exclude Disposals, otherwise as per rule 2\n",
    "                \n",
    "                if winloss in ['In', 'Out']:\n",
    "                    \n",
    "                    for fold in [1, 2, 3, 4, 5]: # 5 Folds of Train-Test Split\n",
    "                        \n",
    "                        # Read in appropriate Train and Test data\n",
    "                        train_data = pd.read_csv(f'./PreparedData/Train_Data_{fold} ({dt}) (B).csv')\n",
    "                        test_games = list(pd.read_csv(f'./PreparedData/Test_Games_List_{fold} ({dt}) (B).csv')['Test Games'])\n",
    "                        \n",
    "                        # Primary filtering of features according to Macro Rules\n",
    "                        if use in ['BT', 'OT']:\n",
    "                            # Accounts for Winloss inclusion choice\n",
    "                            if winloss:\n",
    "                                cols = [col for col in train_data.columns if (f'{use}{dt}' in col or 'Winloss' in col)]\n",
    "                            \n",
    "                            else:\n",
    "                                cols = [col for col in train_data.columns if (f'{use}{dt}' in col)]\n",
    "                                \n",
    "                        else:\n",
    "                            # Accounts for Winloss inclusion choice\n",
    "                            if winloss:\n",
    "                                cols = [col for col in train_data.columns if (f'BT{dt}' in col or f'OT{dt}' in col or 'Winloss' in col)]\n",
    "                            \n",
    "                            else:\n",
    "                                cols = [col for col in train_data.columns if (f'BT{dt}' in col or f'OT{dt}' in col)]\n",
    "                        \n",
    "                        # Calculates correlation and only accept columns that have surpassed FS_Val\n",
    "                        corr = dict()\n",
    "                        for col in cols:\n",
    "                            corr[col] = train_data[[col, 'Brownlow Votes']].corr(method = 'pearson').loc[col]['Brownlow Votes']\n",
    "    \n",
    "                        corr = list(corr.items())\n",
    "                        \n",
    "                        selected_features = [col[0] for col in corr if col[1] > FS_val]\n",
    "                        \n",
    "                        # Put into feature_selection2 function to do secondary filtering based on the FS_rule and BT_OT (or not)\n",
    "                        selected_features = feature_selection2(selected_features, FS_rule, BT_OT)\n",
    "                        \n",
    "                        # Initialises a blank dataframe for this test sample\n",
    "                        cent_storage_cols = {'Method': ['LR(B)'], 'Datatype': [dt], 'Use': [use], 'Feature Selection Value': [FS_val], \n",
    "                                             'Feature Selection Rule': [FS_rule], 'Winloss': [winloss], 'Fold': [fold], 'TP0': [None], \n",
    "                                             'TP0.5': [None], 'TP1': [None], 'TP2': [None], 'TP3': [None], 'Coef1': [None], 'Coef2': [None],\n",
    "                                            'P1': [None], 'V1': [None],\n",
    "                                            'P2': [None], 'V2': [None],\n",
    "                                            'P3': [None], 'V3': [None],\n",
    "                                            'P4': [None], 'V4': [None],\n",
    "                                            'P5': [None], 'V5': [None],\n",
    "                                            'P6': [None], 'V6': [None],\n",
    "                                            'P7': [None], 'V7': [None],\n",
    "                                            'P8': [None], 'V8': [None],\n",
    "                                            'P9': [None], 'V9': [None],\n",
    "                                            'P10': [None], 'V10': [None],\n",
    "                                            'P11': [None], 'V11': [None],\n",
    "                                            'P12': [None], 'V12': [None],\n",
    "                                            'P13': [None], 'V13': [None],\n",
    "                                            'P14': [None], 'V14': [None],\n",
    "                                            'P15': [None], 'V15': [None],\n",
    "                                            'P16': [None], 'V16': [None],\n",
    "                                            'P17': [None], 'V17': [None],\n",
    "                                            'P18': [None], 'V18': [None],\n",
    "                                            'P19': [None], 'V19': [None],\n",
    "                                            'P20': [None], 'V20': [None]}\n",
    "                        \n",
    "                        if not selected_features:\n",
    "                            # Adds it onto our Dataframe for writing onto Central Database later\n",
    "                            Central_Statistics = Central_Statistics.append(pd.DataFrame(cent_storage_cols))\n",
    "                            continue\n",
    "                        \n",
    "                        # Prepare data for Training\n",
    "                        traindata_x = train_data[selected_features]\n",
    "                        traindata_x.index = range(0,len(traindata_x))\n",
    "                        traindata_y = train_data['Brownlow Votes']\n",
    "                        traindata_y.index = range(0,len(traindata_y))\n",
    "                        \n",
    "                        # Train model\n",
    "                        lm = linear_model.LinearRegression()\n",
    "                        traindata_x = traindata_x.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "                        model = lm.fit(traindata_x, traindata_y)\n",
    "                        \n",
    "                        # Perform predictions and collect predictions and actual observations into one dataframe\n",
    "                        out = predict_mass(test_games, lm, selected_features, choice[dt])\n",
    "                        \n",
    "                        # Performs testing on test case and collect stats for true positive of 0, 1, 2 and 3 (as a tuple tp)\n",
    "                        tp = test_mass(out)\n",
    "                        \n",
    "                        # Performs emperical testing on 2021 season\n",
    "                        leaderboard = wholeseason(final_test_games, lm, selected_features, choice[dt])\n",
    "                        \n",
    "                        # Collects the pearsons coefficient for this model\n",
    "                        pears_co = lm.score(traindata_x, traindata_y)\n",
    "                        \n",
    "                        # Initialises a dataframe for this test sample, beginning to fill in some of the statistics\n",
    "                        cent_storage_cols = {'Method': ['LR(B)'], 'Datatype': [dt], 'Use': [use], 'Feature Selection Value': [FS_val], \n",
    "                                             'Feature Selection Rule': [FS_rule], 'Winloss': [winloss], 'Fold': [fold], 'TP0': [tp[0]], \n",
    "                                             'TP0.5': [None], 'TP1': [tp[1]], 'TP2': [tp[2]], 'TP3': [tp[3]], 'Coef1': [pears_co], 'Coef2': [None],\n",
    "                                            'P1': list(), 'V1': list(),\n",
    "                                            'P2': list(), 'V2': list(),\n",
    "                                            'P3': list(), 'V3': list(),\n",
    "                                            'P4': list(), 'V4': list(),\n",
    "                                            'P5': list(), 'V5': list(),\n",
    "                                            'P6': list(), 'V6': list(),\n",
    "                                            'P7': list(), 'V7': list(),\n",
    "                                            'P8': list(), 'V8': list(),\n",
    "                                            'P9': list(), 'V9': list(),\n",
    "                                            'P10': list(), 'V10': list(),\n",
    "                                            'P11': list(), 'V11': list(),\n",
    "                                            'P12': list(), 'V12': list(),\n",
    "                                            'P13': list(), 'V13': list(),\n",
    "                                            'P14': list(), 'V14': list(),\n",
    "                                            'P15': list(), 'V15': list(),\n",
    "                                            'P16': list(), 'V16': list(),\n",
    "                                            'P17': list(), 'V17': list(),\n",
    "                                            'P18': list(), 'V18': list(),\n",
    "                                            'P19': list(), 'V19': list(),\n",
    "                                            'P20': list(), 'V20': list()}\n",
    "                        # Fill in emperical observations\n",
    "                        for i in range(1, 21):\n",
    "                            cent_storage_cols[f'P{i}'].append(leaderboard[i-1][0])\n",
    "                            cent_storage_cols[f'V{i}'].append(leaderboard[i-1][1])\n",
    "                        \n",
    "                        # Adds it onto our Dataframe for writing onto Central Database later\n",
    "                        Central_Statistics = Central_Statistics.append(pd.DataFrame(cent_storage_cols))\n",
    "                    \n",
    "                    # Write the Dataframe (consisting 10 models and their statistics) out\n",
    "                        # Chose to do it in batch of 10 to conserve computational power.\n",
    "                        # But must output regularly as the full block takes up to 10 hours to run - if fail somewhere in between need a method to salvage results.\n",
    "                    Central_Statistics.to_csv('Central_Statistics.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: A few improvements could be made on this notebook: ##\n",
    "\n",
    "*1. To further save computational time, could consider switching up order of iteration (although that may be dangerous as it doesn't guarentee we are reading correct copy in from files each time*\n",
    "\n",
    "*2. A mechanism for starting loop at predetermined point (in case fails half way - don't want to waste previous computation time). Would be useful for future projects that does mass testing*\n",
    "\n",
    "*-an idea is to perhaps try turn iterations first into a list, and then iterate through the list. Thus at failpoint, could salvage the iterator index that it was up to and restart from list[i] using list[i:].*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
