{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model 1. (B)-N-BT-0.2-2 ##\n",
    "\n",
    "Trains model 1 based on:\n",
    "\n",
    "- Bootstrapped Linear Regression\n",
    "- Normalised Data \n",
    "- Both Teams data\n",
    "- FS_Val 0.2\n",
    "- FS_Rule 2\n",
    "\n",
    "**Author: `Lang (Ron) Chen` 2021.12-2022.1**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from BrownlowPredictorTools.predict import predict\n",
    "from BrownlowPredictorTools.test import test\n",
    "from BrownlowPredictorTools.return_tp import return_tp\n",
    "from BrownlowPredictorTools.wholeseason import wholeseason\n",
    "from BrownlowPredictorTools.feature_selection2 import feature_selection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 'NormalisedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = os.listdir(f'./Data/{choice}')[1:]\n",
    "filelist.sort()\n",
    "filelist = filelist[1:]\n",
    "# Remove the first file (an ipynb checkpoint file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we need to perform tests to evaluate this final model, still need to use do this\n",
    "\n",
    "# Gets list of emperical test games (full 2021 season)\n",
    "final_test_games = [file for file in filelist if '2021' in file]\n",
    "\n",
    "# Gathers full games list (except 2021) and performs a single Train-Test Split (note different from previous KFold)\n",
    "test_train_games = [file for file in filelist if '2021' not in file]\n",
    "train_games, test_games = train_test_split(test_train_games, train_size = 0.8, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pre-prepared sample data of trained data only \n",
    "# (the same rows as if we used concatenated all the data from the train_games list)\n",
    "train_data = pd.read_csv('./Models/TrainingData/M1_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstraps data\n",
    "        \n",
    "# Picks out data labelled 1 vote, 2 votes, 3 votes \n",
    "zero = train_data[train_data['Brownlow Votes'] == 0]\n",
    "one = train_data[train_data['Brownlow Votes'] == 1]\n",
    "two = train_data[train_data['Brownlow Votes'] == 2]\n",
    "three = train_data[train_data['Brownlow Votes'] == 3]\n",
    "\n",
    "# Sample them so each has same number as 0 votes\n",
    "new_one = one.sample(n = len(zero), replace = True, random_state = 42)\n",
    "new_two = two.sample(n = len(zero), replace = True, random_state = 42)\n",
    "new_three = three.sample(n = len(zero), replace = True, random_state = 42)\n",
    "\n",
    "# Add the sampled dataframes back onto zero\n",
    "bootstrapped_data = pd.concat([zero, new_one, new_two, new_three], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Disposals BTN',\n",
       " 'Goals BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Centre Clearances BTN',\n",
       " 'Stoppage Clearances BTN',\n",
       " 'Score Involvements BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Behind Assists BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Columns of Both Teams Stats only\n",
    "cols = [col for col in train_data.columns if ('BTN' in col or 'Winloss' in col)]\n",
    "\n",
    "# Select Columns with correlation higher than 0.2 only\n",
    "corr = dict()\n",
    "for col in cols:\n",
    "    corr[col] = train_data[[col, 'Brownlow Votes']].corr(method = 'pearson').loc[col]['Brownlow Votes']\n",
    "\n",
    "corr = list(corr.items())\n",
    "\n",
    "selected_features = [col[0] for col in corr if col[1] > 0.2]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Trains Model using rule 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Marks BTN',\n",
       " 'Goals BTN',\n",
       " 'Behinds BTN',\n",
       " 'Tackles BTN',\n",
       " 'Hitouts BTN',\n",
       " 'Goal Assists BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Clangers BTN',\n",
       " 'Rebound 50s BTN',\n",
       " 'Frees For BTN',\n",
       " 'Frees Agains BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'One Percenters BTN',\n",
       " 'Bounces BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Turnovers BTN',\n",
       " 'Intercepts BTN',\n",
       " 'Time On Ground % BTN',\n",
       " 'Winloss',\n",
       " 'Behind Assists BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = feature_selection2(cols, 2, False)\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_x = train_data[selected_features]\n",
    "traindata_x.index = range(0,len(traindata_x))\n",
    "traindata_y = train_data['Brownlow Votes']\n",
    "traindata_y.index = range(0,len(traindata_y))\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "traindata_x = traindata_x.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "model = lm.fit(traindata_x, traindata_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, testdata_y = predict(test_games, lm, selected_features, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1, result2 = test(predictions, testdata_y, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9725210352540207,\n",
       "  0.013313451911811694,\n",
       "  0.010011715837682395,\n",
       "  0.004153796996485249],\n",
       " [0.5938864628820961,\n",
       "  0.18340611353711792,\n",
       "  0.11353711790393013,\n",
       "  0.1091703056768559],\n",
       " [0.3624454148471616,\n",
       "  0.14410480349344978,\n",
       "  0.26200873362445415,\n",
       "  0.2314410480349345],\n",
       " [0.1703056768558952,\n",
       "  0.12663755458515283,\n",
       "  0.21397379912663755,\n",
       "  0.4890829694323144]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9725210352540207,\n",
       "  0.014485035680051123,\n",
       "  0.008840132069442966,\n",
       "  0.004153796996485249],\n",
       " [0.5458515283842795,\n",
       "  0.18340611353711792,\n",
       "  0.14410480349344978,\n",
       "  0.12663755458515283],\n",
       " [0.4104803493449782,\n",
       "  0.11353711790393013,\n",
       "  0.26200873362445415,\n",
       "  0.21397379912663755],\n",
       " [0.1703056768558952,\n",
       "  0.1091703056768559,\n",
       "  0.2314410480349345,\n",
       "  0.4890829694323144]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9725210352540207,\n",
       " 0.18340611353711792,\n",
       " 0.26200873362445415,\n",
       " 0.4890829694323144)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_tp(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Summary Observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Emperical Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the season 2021 data onto predictor and gets top players\n",
    "leaderboard = wholeseason(final_test_games, lm, selected_features, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jack Steele', 39),\n",
       " ('Oliver Wines', 34),\n",
       " ('Clayton Oliver', 29),\n",
       " ('Marcus Bontempelli', 29),\n",
       " ('Christian Petracca', 28),\n",
       " ('Darcy Parish', 28),\n",
       " ('Jarryd Lyons', 26),\n",
       " ('Luke Parker', 24),\n",
       " ('Jackson Macrae', 21),\n",
       " ('Rory Laird', 21),\n",
       " ('Tom Mitchell', 20),\n",
       " ('Travis Boak', 20),\n",
       " ('Touk Miller', 19),\n",
       " ('Sam Walsh', 18),\n",
       " ('Jake Stringer', 18)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Predictor's r scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2465957489737035\n"
     ]
    }
   ],
   "source": [
    "print(lm.score(traindata_x, traindata_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Picklising**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Models/M1.pickle', 'wb') as f:\n",
    "    pickle.dump([lm, selected_features, choice], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
