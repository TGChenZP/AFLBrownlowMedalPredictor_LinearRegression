{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Concept 1. (Basic) Linear Regression using Normalised Data/Both Teams #\n",
    "## For Brownlow Predictor Project ##\n",
    "\n",
    "Trains up 4 models using the 4 Macro Rules of Feature Selection using Normalised Data/Both Team Columns Only (FS_Val = 0.2 and Includes Winloss)\n",
    "\n",
    "**Author: `Lang (Ron) Chen` 2021.12-2022.1**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "from BrownlowPredictorTools.predict import predict\n",
    "from BrownlowPredictorTools.test import test\n",
    "from BrownlowPredictorTools.return_tp import return_tp\n",
    "from BrownlowPredictorTools.wholeseason import wholeseason\n",
    "from BrownlowPredictorTools.feature_selection2 import feature_selection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 'NormalisedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = os.listdir(f'./Data/{choice}')[1:]\n",
    "# Remove the first file (an ipynb checkpoint file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets list of emperical test games (full 2021 season)\n",
    "final_test_games = [file for file in filelist if '2021' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathers full games list (except 2021) and performs a single Train-Test Split (note different from previous KFold)\n",
    "test_train_games = [file for file in filelist if '2021' not in file]\n",
    "train_games, test_games = train_test_split(test_train_games, train_size = 0.8, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pre-prepared sample data of trained data only \n",
    "# (the same rows as if we used concatenated all the data from the train_games list)\n",
    "train_data = pd.read_csv('Train_Data (N).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Disposals BTN',\n",
       " 'Marks BTN',\n",
       " 'Goals BTN',\n",
       " 'Behinds BTN',\n",
       " 'Tackles BTN',\n",
       " 'Hitouts BTN',\n",
       " 'Goal Assists BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Clangers BTN',\n",
       " 'Rebound 50s BTN',\n",
       " 'Frees For BTN',\n",
       " 'Frees Agains BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Contested Marks BTN',\n",
       " 'Marks Inside 50 BTN',\n",
       " 'One Percenters BTN',\n",
       " 'Bounces BTN',\n",
       " 'Centre Clearances BTN',\n",
       " 'Stoppage Clearances BTN',\n",
       " 'Score Involvements BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Turnovers BTN',\n",
       " 'Intercepts BTN',\n",
       " 'Tackles Inside 50 BTN',\n",
       " 'Time On Ground % BTN',\n",
       " 'Winloss',\n",
       " 'Uncontested Marks BTN',\n",
       " 'Marks Outside 50 BTN',\n",
       " 'Tackles Outside 50 BTN',\n",
       " 'Behind Assists BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Columns of Both Teams Stats only\n",
    "cols = [col for col in train_data.columns if ('BTN' in col or 'Winloss' in col)]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Kicks BTN': 0.3313800478557236,\n",
       " 'Handballs BTN': 0.28243847810008826,\n",
       " 'Disposals BTN': 0.3848565320688732,\n",
       " 'Marks BTN': 0.16831020314626322,\n",
       " 'Goals BTN': 0.251159108505028,\n",
       " 'Behinds BTN': 0.09716864795537491,\n",
       " 'Tackles BTN': 0.15068595304633947,\n",
       " 'Hitouts BTN': 0.015309775486725926,\n",
       " 'Goal Assists BTN': 0.1261109371515187,\n",
       " 'Inside 50s BTN': 0.2586408367327942,\n",
       " 'Clearances BTN': 0.30912151700818563,\n",
       " 'Clangers BTN': -0.12145252365952025,\n",
       " 'Rebound 50s BTN': 0.030801676287350914,\n",
       " 'Frees For BTN': 0.15666458356544574,\n",
       " 'Frees Agains BTN': -0.03362877080488017,\n",
       " 'Contested Possessions BTN': 0.3522270859288417,\n",
       " 'Uncontested Possessions BTN': 0.273743999465288,\n",
       " 'Effective Disposals BTN': 0.34924408871707774,\n",
       " 'Contested Marks BTN': 0.09026198685114628,\n",
       " 'Marks Inside 50 BTN': 0.15444090495732277,\n",
       " 'One Percenters BTN': -0.05126795234854484,\n",
       " 'Bounces BTN': 0.07938363883800453,\n",
       " 'Centre Clearances BTN': 0.25838896514746523,\n",
       " 'Stoppage Clearances BTN': 0.2705823274328926,\n",
       " 'Score Involvements BTN': 0.3480827519673654,\n",
       " 'Metres Gained BTN': 0.2939421260115884,\n",
       " 'Turnovers BTN': -0.175119864251332,\n",
       " 'Intercepts BTN': 0.04602109096732197,\n",
       " 'Tackles Inside 50 BTN': 0.06579797399084476,\n",
       " 'Time On Ground % BTN': 0.073272895140768,\n",
       " 'Winloss': 0.1625048747349721,\n",
       " 'Uncontested Marks BTN': 0.14425694376377834,\n",
       " 'Marks Outside 50 BTN': 0.10557227682048663,\n",
       " 'Tackles Outside 50 BTN': 0.1395946916164612,\n",
       " 'Behind Assists BTN': 0.3410061854851594,\n",
       " 'Ineffective Disposals BTN': 0.2744215460404771}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Columns with correlation higher than 0.2 only\n",
    "corr = dict()\n",
    "for col in cols:\n",
    "    corr[col] = train_data[[col, 'Brownlow Votes']].corr(method = 'pearson').loc[col]['Brownlow Votes']\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kicks BTN', 0.3313800478557236),\n",
       " ('Handballs BTN', 0.28243847810008826),\n",
       " ('Disposals BTN', 0.3848565320688732),\n",
       " ('Marks BTN', 0.16831020314626322),\n",
       " ('Goals BTN', 0.251159108505028),\n",
       " ('Behinds BTN', 0.09716864795537491),\n",
       " ('Tackles BTN', 0.15068595304633947),\n",
       " ('Hitouts BTN', 0.015309775486725926),\n",
       " ('Goal Assists BTN', 0.1261109371515187),\n",
       " ('Inside 50s BTN', 0.2586408367327942),\n",
       " ('Clearances BTN', 0.30912151700818563),\n",
       " ('Clangers BTN', -0.12145252365952025),\n",
       " ('Rebound 50s BTN', 0.030801676287350914),\n",
       " ('Frees For BTN', 0.15666458356544574),\n",
       " ('Frees Agains BTN', -0.03362877080488017),\n",
       " ('Contested Possessions BTN', 0.3522270859288417),\n",
       " ('Uncontested Possessions BTN', 0.273743999465288),\n",
       " ('Effective Disposals BTN', 0.34924408871707774),\n",
       " ('Contested Marks BTN', 0.09026198685114628),\n",
       " ('Marks Inside 50 BTN', 0.15444090495732277),\n",
       " ('One Percenters BTN', -0.05126795234854484),\n",
       " ('Bounces BTN', 0.07938363883800453),\n",
       " ('Centre Clearances BTN', 0.25838896514746523),\n",
       " ('Stoppage Clearances BTN', 0.2705823274328926),\n",
       " ('Score Involvements BTN', 0.3480827519673654),\n",
       " ('Metres Gained BTN', 0.2939421260115884),\n",
       " ('Turnovers BTN', -0.175119864251332),\n",
       " ('Intercepts BTN', 0.04602109096732197),\n",
       " ('Tackles Inside 50 BTN', 0.06579797399084476),\n",
       " ('Time On Ground % BTN', 0.073272895140768),\n",
       " ('Winloss', 0.1625048747349721),\n",
       " ('Uncontested Marks BTN', 0.14425694376377834),\n",
       " ('Marks Outside 50 BTN', 0.10557227682048663),\n",
       " ('Tackles Outside 50 BTN', 0.1395946916164612),\n",
       " ('Behind Assists BTN', 0.3410061854851594),\n",
       " ('Ineffective Disposals BTN', 0.2744215460404771)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = list(corr.items())\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Disposals BTN',\n",
       " 'Goals BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Centre Clearances BTN',\n",
       " 'Stoppage Clearances BTN',\n",
       " 'Score Involvements BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Behind Assists BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = [col[0] for col in corr if col[1] > 0.2]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Trains Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Demonstration of functions (completely same as those in libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection2(cols, select_mode, BT_OT):\n",
    "    \"\"\" Helper function for feature selection based on rules of Feature Selection. First parameter is the , second parameter is the micro rules of feature \n",
    "    selection (1, 2, 3, 4), third parameter denotes whether macro rule of feature selection is 'BT_OT' \"\"\"\n",
    "    \n",
    "    out = list()\n",
    "    \n",
    "    # dictionary listing items that cannot coexist with each other\n",
    "    nonallowed = {'Kicks': [\"Disposals\"],\n",
    "         'Handballs': [\"Disposals\"],\n",
    "         'Disposals': [\"Kicks\", \"Handballs\", 'Ineffective Disposals', 'Contested Possessions', 'Uncontested Possessions', 'Effective Disposals'],\n",
    "         'Marks': [\"Uncontested Marks\", 'Marks Outside 50', 'Marks Inside 50', 'Contested Marks'],\n",
    "         'Tackles': ['Tackles Inside 50', 'Tackles Outside 50'],\n",
    "         'Goal Assists': [\"Score Involvements\"],\n",
    "         'Clearances': [\"Centre Clearances\", \"Stoppage Clearances\"],\n",
    "         'Contested Possessions': [\"Disposals\"],\n",
    "         'Uncontested Possessions': [\"Disposals\"],\n",
    "         'Effective Disposals': [\"Disposals\"],\n",
    "         'Contested Marks': ['Marks'],\n",
    "         'Marks Inside 50': ['Marks'],\n",
    "         'Centre Clearances': ['Clearances'],\n",
    "         'Stoppage Clearances': ['Clearances'],\n",
    "         'Score Involvements': ['Behind Assists', 'Goal Assists'],\n",
    "         'Tackles Inside 50': [\"Tackles\"],\n",
    "         'Uncontested Marks': [\"Marks\"],\n",
    "         'Marks Outside 50': [\"Marks\"],\n",
    "         'Tackles Outside 50': [\"Tackles\"],\n",
    "         'Behind Assists BTN': [\"Score Involvements\"],\n",
    "         'Ineffective Disposals': [\"Disposals\"]}    \n",
    "    \n",
    "    if select_mode == 1 and not BT_OT: # Micro mode 1: return all that is seen\n",
    "        return cols\n",
    "    \n",
    "    illegal = list()\n",
    "    \n",
    "    if select_mode == 3: # Micro mode 3: ban summary statistics\n",
    "        banned = ['Disposals', 'Marks', 'Tackles', 'Clearances', 'Score Involvements']\n",
    "        illegal.extend(banned)\n",
    "        \n",
    "    elif select_mode == 4: # Micro mode 4: ban Disposals\n",
    "        illegal.append('Disposals')\n",
    "    \n",
    "    \n",
    "    \n",
    "    if BT_OT and select_mode != 1:\n",
    "        \n",
    "        for col in cols:\n",
    "            col_ = strip_end(col)\n",
    "\n",
    "            if col_ not in illegal:\n",
    "\n",
    "                if col_ in nonallowed:\n",
    "\n",
    "                    for i in range(len(nonallowed[col_])):\n",
    "                        illegal.append(nonallowed[col_][i])\n",
    "                \n",
    "                illegal.append(col_)\n",
    "                out.append(col)\n",
    "    \n",
    "    \n",
    "    elif BT_OT and select_mode == 1: \n",
    "        \n",
    "        for col in cols:\n",
    "            col_ = strip_end(col)\n",
    "\n",
    "            if col_ not in illegal:\n",
    "                \n",
    "                # BT or OT: i.e. once BT uses something, then put the col's root name in illegal so OT can't be selected even if it surpassed FT_val\n",
    "                illegal.append(col_) \n",
    "                out.append(col)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        for col in cols:\n",
    "            col_ = strip_end(col)\n",
    "\n",
    "            if col_ not in illegal:\n",
    "\n",
    "                if col_ in nonallowed:\n",
    "\n",
    "                    for i in range(len(nonallowed[col_])):\n",
    "                        illegal.append(nonallowed[col_][i])\n",
    "\n",
    "                out.append(col)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def strip_end(string):\n",
    "    \"\"\" Helper function to remove the 'BTS' 'BTN' tag from end \"\"\"\n",
    "    \n",
    "    tmp = string.split()\n",
    "    out = str()\n",
    "    \n",
    "    for i in range(len(tmp)-1):\n",
    "        out += tmp[i]\n",
    "        out += ' '\n",
    "    \n",
    "    return out[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "def predict(test_games, lm, selected_features, choice):\n",
    "    \"\"\" takes test_games and model to output predictions as a list and observations as a Series \"\"\"\n",
    "    \n",
    "    prediction = list()\n",
    "    \n",
    "    testdata_y = pd.DataFrame()\n",
    "    \n",
    "    for file in test_games:\n",
    "        \n",
    "        # Open test game file\n",
    "        df = pd.read_csv(f'./Data/{choice}/{file}')\n",
    "        \n",
    "        # Initialise a list for this game\n",
    "        tmp = [0 for i in range(len(df))]\n",
    "        \n",
    "        # Make predictions\n",
    "        x_final = df[selected_features].replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "        y_pred = lm.predict(x_final)\n",
    "        \n",
    "        # Collect the actual observations\n",
    "        testdata_y = pd.concat([testdata_y, df['Brownlow Votes']], axis=0)\n",
    "        \n",
    "        # Find top 3 scoring players for the game and allocate 3, 2, 1 votes to their respective index on the tmp list\n",
    "        enumerated = [(i, score) for i, score in enumerate(y_pred)]\n",
    "        enumerated.sort(key = lambda x:x[1], reverse = True)\n",
    "        \n",
    "        tmp[enumerated[0][0]] = 3\n",
    "        tmp[enumerated[1][0]] = 2\n",
    "        tmp[enumerated[2][0]] = 1\n",
    "        \n",
    "        # Can un-comment to observe what actual scores the linear regression is outputting \n",
    "#         print(enumerated[0:3])\n",
    "#         print(enumerated[-3:])\n",
    "        \n",
    "        prediction = prediction + tmp\n",
    "    \n",
    "    return prediction, testdata_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(predictions, testdata_y, nchoice):\n",
    "    \"\"\" Calculates the tp/tn for 0 votes, 1 vote, 2 votes and 3 votes. Polymorphic as to how many choices there are \"\"\"\n",
    "    \n",
    "    # instantiate tally\n",
    "    result1 = list() # tp/tn/tp/fp calculated with respect to predictions (i.e. predicted 1, obs 0 => contribute to fp 1)\n",
    "    result2 = list() # tp/tn/tp/fp calculated with respect to observations (i.e. predicted 1, obs 0 => contribute to fp 0)\n",
    "    \n",
    "    # Initialise the result1 and result2 tallys based on nchoice\n",
    "    for i in range(nchoice):\n",
    "        tmp1 = [0 for j in range(nchoice)]\n",
    "        tmp2 = [0 for j in range(nchoice)]\n",
    "        result1.append(tmp1)\n",
    "        result2.append(tmp2)\n",
    "    \n",
    "    # Run through the predictions and add to tally according to whether it is tp/tn/fp/fn\n",
    "    for i in range(len(predictions)):\n",
    "        result1[predictions[i]][int(testdata_y.iloc[i][0])] += 1\n",
    "        result2[int(testdata_y.iloc[i][0])][predictions[i]] += 1\n",
    "    \n",
    "    # Find the sum of each row and then take percentage based on it (because we are taking tp/fp/tn/fn with respect to either predictions or observations rather than total)\n",
    "    for i in range(nchoice):\n",
    "        \n",
    "        sum_row1 = sum(result1[i])\n",
    "        sum_row2 = sum(result2[i])\n",
    "        \n",
    "        for j in range(nchoice):\n",
    "            result1[i][j] = result1[i][j]/sum_row1\n",
    "            result2[i][j] = result2[i][j]/sum_row2\n",
    "            \n",
    "    return result1, result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_tp(result):\n",
    "    \"\"\" Helper function for just returning the true positive/true negative values\"\"\"\n",
    "    \n",
    "    return tuple([result[i][i] for i in range(len(result))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also avaliable is the predict_mass and test_mass functions used in the scripts - not used in Proof of Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "def predict_mass(test_games, lm, selected_features, choice):\n",
    "    \"\"\" same as predict except returns both the predict and observations in one dataframe \"\"\"\n",
    "    \n",
    "    prediction = list()\n",
    "    \n",
    "    testdata_y = pd.DataFrame()\n",
    "    \n",
    "    for file in test_games:\n",
    "        \n",
    "        # Open test game file\n",
    "        df = pd.read_csv(f'./Data/{choice}/{file}')\n",
    "        \n",
    "        # Initialise a list for this game\n",
    "        tmp = [0 for i in range(len(df))]\n",
    "        \n",
    "        # Make predictions\n",
    "        x_final = df[selected_features].replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "        y_pred = lm.predict(x_final)\n",
    "        \n",
    "        # Collect the actual observations\n",
    "        testdata_y = pd.concat([testdata_y, df['Brownlow Votes']], axis=0)\n",
    "        \n",
    "        # Find top 3 scoring players for the game and allocate 3, 2, 1 votes to their respective index on the tmp list\n",
    "        enumerated = [(i, score) for i, score in enumerate(y_pred)]\n",
    "        enumerated.sort(key = lambda x:x[1], reverse = True)\n",
    "        \n",
    "        tmp[enumerated[0][0]] = 3\n",
    "        tmp[enumerated[1][0]] = 2\n",
    "        tmp[enumerated[2][0]] = 1\n",
    "        \n",
    "        # Can un-comment to observe what actual scores the linear regression is outputting \n",
    "#         print(enumerated[0:3])\n",
    "#         print(enumerated[-3:])\n",
    "        \n",
    "        prediction = prediction + tmp\n",
    "        \n",
    "    out = pd.DataFrame({'predictions': prediction, 'observations': list(testdata_y[testdata_y.columns[0]])})\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mass(out): \n",
    "    \"\"\" Helper function for returning tp/tn for mass testing (more efficient as does not collect other stats)\"\"\"\n",
    "    \n",
    "    tp0 = len(out[(out['predictions'] == out['observations'].astype(int)) & (out['predictions'] == 0)])/len(out[(out['predictions'] == 0)])\n",
    "    tp1 = len(out[(out['predictions'] == out['observations'].astype(int)) & (out['predictions'] == 1)])/len(out[(out['predictions'] == 1)])\n",
    "    tp2 = len(out[(out['predictions'] == out['observations'].astype(int)) & (out['predictions'] == 2)])/len(out[(out['predictions'] == 2)])\n",
    "    tp3 = len(out[(out['predictions'] == out['observations'].astype(int)) & (out['predictions'] == 3)])/len(out[(out['predictions'] == 3)])\n",
    "    \n",
    "    return (tp0, tp1, tp2, tp3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Micro Rule of Feature Selection 1: \n",
    "\n",
    "*All cols that passed FS_val selected*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains LR model\n",
    "traindata_x_1 = train_data[selected_features]\n",
    "traindata_x_1.index = range(0,len(traindata_x_1))\n",
    "traindata_y_1 = train_data['Brownlow Votes']\n",
    "traindata_y_1.index = range(0,len(traindata_y_1))\n",
    "\n",
    "lm_1 = linear_model.LinearRegression()\n",
    "traindata_x_1 = traindata_x_1.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "model_1 = lm_1.fit(traindata_x_1, traindata_y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and observations\n",
    "predictions_1, testdata_y_1 = predict(test_games, lm_1, selected_features, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get True Positive/True Negative results\n",
    "result1_1, result2_1 = test(predictions_1, testdata_y_1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9698583448716583,\n",
       "  0.013632974757695175,\n",
       "  0.01139631483651081,\n",
       "  0.00511236553413569],\n",
       " [0.6200873362445415,\n",
       "  0.17903930131004367,\n",
       "  0.09606986899563319,\n",
       "  0.10480349344978165],\n",
       " [0.4148471615720524,\n",
       "  0.1222707423580786,\n",
       "  0.21397379912663755,\n",
       "  0.24890829694323144],\n",
       " [0.20087336244541484,\n",
       "  0.13973799126637554,\n",
       "  0.22270742358078602,\n",
       "  0.4366812227074236]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP/TN based on what was predicted\n",
    "result1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9698583448716583,\n",
       "  0.015124081371818084,\n",
       "  0.010118223452976888,\n",
       "  0.004899350303546704],\n",
       " [0.5589519650655022,\n",
       "  0.17903930131004367,\n",
       "  0.1222707423580786,\n",
       "  0.13973799126637554],\n",
       " [0.4672489082969432,\n",
       "  0.09606986899563319,\n",
       "  0.21397379912663755,\n",
       "  0.22270742358078602],\n",
       " [0.2096069868995633,\n",
       "  0.10480349344978165,\n",
       "  0.24890829694323144,\n",
       "  0.4366812227074236]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP/TN based on what was observed\n",
    "result2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9698583448716583,\n",
       " 0.17903930131004367,\n",
       " 0.21397379912663755,\n",
       " 0.4366812227074236)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only the True Positive Values\n",
    "return_tp(result1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Micro Rule of Feature Selection 2\n",
    "\n",
    "*-For those with dependency/triangle relationships (i.e. A=Disposals/B=Kicks/C=Handballs), if A comes first then B, C excluded. If B or C comes first then A excluded*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Goals BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Score Involvements BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selects feature according to micro FS_Rule\n",
    "selected_features_2 = feature_selection2(selected_features, 2, False)\n",
    "selected_features_2\n",
    "\n",
    "#All other operations hereonin same as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_x_2 = train_data[selected_features_2]\n",
    "traindata_x_2.index = range(0,len(traindata_x_2))\n",
    "traindata_y_2 = train_data['Brownlow Votes']\n",
    "traindata_y_2.index = range(0,len(traindata_y_2))\n",
    "\n",
    "lm_2 = linear_model.LinearRegression()\n",
    "traindata_x_2 = traindata_x_2.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "model_2 = lm_2.fit(traindata_x_2, traindata_y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2, testdata_y_2 = predict(test_games, lm_2, selected_features_2, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1_2, result2_2 = test(predictions_2, testdata_y_2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9698583448716583,\n",
       "  0.013952497603578655,\n",
       "  0.01107679199062733,\n",
       "  0.00511236553413569],\n",
       " [0.6200873362445415,\n",
       "  0.1703056768558952,\n",
       "  0.1091703056768559,\n",
       "  0.10043668122270742],\n",
       " [0.4366812227074236,\n",
       "  0.1222707423580786,\n",
       "  0.2052401746724891,\n",
       "  0.23580786026200873],\n",
       " [0.17903930131004367,\n",
       "  0.13537117903930132,\n",
       "  0.2314410480349345,\n",
       "  0.45414847161572053]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9698583448716583,\n",
       "  0.015124081371818084,\n",
       "  0.010650761529449356,\n",
       "  0.004366812227074236],\n",
       " [0.5720524017467249,\n",
       "  0.1703056768558952,\n",
       "  0.1222707423580786,\n",
       "  0.13537117903930132],\n",
       " [0.45414847161572053,\n",
       "  0.1091703056768559,\n",
       "  0.2052401746724891,\n",
       "  0.2314410480349345],\n",
       " [0.2096069868995633,\n",
       "  0.10043668122270742,\n",
       "  0.23580786026200873,\n",
       "  0.45414847161572053]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9698583448716583,\n",
       " 0.1703056768558952,\n",
       " 0.2052401746724891,\n",
       " 0.45414847161572053)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_tp(result1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Micro Rule of Feature Selection 3: \n",
    "\n",
    "*All cols that passed FS_val selected but abandon all 'summary' cols such as Disposal/Tackles/Marks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Goals BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Centre Clearances BTN',\n",
       " 'Stoppage Clearances BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Behind Assists BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_3 = feature_selection2(selected_features, 3, False)\n",
    "selected_features_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_x_3 = train_data[selected_features_3]\n",
    "traindata_x_3.index = range(0,len(traindata_x_3))\n",
    "traindata_y_3 = train_data['Brownlow Votes']\n",
    "traindata_y_3.index = range(0,len(traindata_y_3))\n",
    "\n",
    "lm_3 = linear_model.LinearRegression()\n",
    "traindata_x_3 = traindata_x_3.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "model_3 = lm_3.fit(traindata_x_3, traindata_y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_3, testdata_y_3 = predict(test_games, lm_3, selected_features_3, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1_3, result2_3 = test(predictions_3, testdata_y_3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9696453296410693,\n",
       "  0.014165512834167643,\n",
       "  0.011183299605921824,\n",
       "  0.005005857918841197],\n",
       " [0.6419213973799127,\n",
       "  0.14847161572052403,\n",
       "  0.11353711790393013,\n",
       "  0.09606986899563319],\n",
       " [0.42358078602620086,\n",
       "  0.13100436681222707,\n",
       "  0.19213973799126638,\n",
       "  0.25327510917030566],\n",
       " [0.17903930131004367,\n",
       "  0.13973799126637554,\n",
       "  0.23580786026200873,\n",
       "  0.44541484716157204]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9696453296410693,\n",
       "  0.015656619448290554,\n",
       "  0.010331238683565875,\n",
       "  0.004366812227074236],\n",
       " [0.5807860262008734,\n",
       "  0.14847161572052403,\n",
       "  0.13100436681222707,\n",
       "  0.13973799126637554],\n",
       " [0.4585152838427948,\n",
       "  0.11353711790393013,\n",
       "  0.19213973799126638,\n",
       "  0.23580786026200873],\n",
       " [0.2052401746724891,\n",
       "  0.09606986899563319,\n",
       "  0.25327510917030566,\n",
       "  0.44541484716157204]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9696453296410693,\n",
       " 0.14847161572052403,\n",
       " 0.19213973799126638,\n",
       " 0.44541484716157204)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_tp(result1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Micro Rule of Feature Selection 4: \n",
    "\n",
    "*Exclude Disposals, otherwise as per rule 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicks BTN',\n",
       " 'Handballs BTN',\n",
       " 'Goals BTN',\n",
       " 'Inside 50s BTN',\n",
       " 'Clearances BTN',\n",
       " 'Contested Possessions BTN',\n",
       " 'Uncontested Possessions BTN',\n",
       " 'Effective Disposals BTN',\n",
       " 'Score Involvements BTN',\n",
       " 'Metres Gained BTN',\n",
       " 'Ineffective Disposals BTN']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_4 = feature_selection2(selected_features, 4, False)\n",
    "selected_features_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_x_4 = train_data[selected_features_4]\n",
    "traindata_x_4.index = range(0,len(traindata_x_4))\n",
    "traindata_y_4 = train_data['Brownlow Votes']\n",
    "traindata_y_4.index = range(0,len(traindata_y_4))\n",
    "\n",
    "lm_4 = linear_model.LinearRegression()\n",
    "traindata_x_4 = traindata_x_4.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "model_4 = lm_4.fit(traindata_x_4, traindata_y_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_4, testdata_y_4 = predict(test_games, lm_4, selected_features_4, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1_4, result2_4 = test(predictions_4, testdata_y_4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9698583448716583,\n",
       "  0.013952497603578655,\n",
       "  0.01107679199062733,\n",
       "  0.00511236553413569],\n",
       " [0.6200873362445415,\n",
       "  0.1703056768558952,\n",
       "  0.1091703056768559,\n",
       "  0.10043668122270742],\n",
       " [0.4366812227074236,\n",
       "  0.1222707423580786,\n",
       "  0.2052401746724891,\n",
       "  0.23580786026200873],\n",
       " [0.17903930131004367,\n",
       "  0.13537117903930132,\n",
       "  0.2314410480349345,\n",
       "  0.45414847161572053]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9698583448716583,\n",
       "  0.015124081371818084,\n",
       "  0.010650761529449356,\n",
       "  0.004366812227074236],\n",
       " [0.5720524017467249,\n",
       "  0.1703056768558952,\n",
       "  0.1222707423580786,\n",
       "  0.13537117903930132],\n",
       " [0.45414847161572053,\n",
       "  0.1091703056768559,\n",
       "  0.2052401746724891,\n",
       "  0.2314410480349345],\n",
       " [0.2096069868995633,\n",
       "  0.10043668122270742,\n",
       "  0.23580786026200873,\n",
       "  0.45414847161572053]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9698583448716583,\n",
       " 0.1703056768558952,\n",
       " 0.2052401746724891,\n",
       " 0.45414847161572053)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_tp(result1_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Summary Observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Demonstration of functions (completely same as in libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "from collections import defaultdict as dd\n",
    "# import numpy as np\n",
    "\n",
    "def wholeseason(final_test_games, lm, selected_features, choice):\n",
    "    \"\"\" Helper function for running emperical test - returns tuple of leaderboard of players for the season (with votes) \"\"\"\n",
    "    \n",
    "    players = dd(int) # tally\n",
    "    \n",
    "    for file in final_test_games:\n",
    "        \n",
    "        # Open each final test season's game\n",
    "        df = pd.read_csv(f'./Data/{choice}/{file}')\n",
    "        \n",
    "        # Run predictions\n",
    "        x_final = df[selected_features].replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "        y_pred = lm.predict(x_final)\n",
    "        \n",
    "        # Find top 3 scoring players of the game and rank them from highest score to lowest\n",
    "        enumerated = [(i, score) for i, score in enumerate(y_pred)]\n",
    "        enumerated.sort(key = lambda x:x[1], reverse = True)\n",
    "        \n",
    "        # Find their (top 3 players) names and insert them into the tally by adding 3 votes, 2 votes and 1 vote respectively\n",
    "        for j in range(3):\n",
    "            players[df.loc[enumerated[j][0]]['Player']] += (3-j)\n",
    "    \n",
    "    # Sort the leaderboard so top pollers are ranked first\n",
    "    leaderboard = sorted(list(players.items()), reverse = True, key = lambda x:x[1])\n",
    "    \n",
    "    return leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Emperical Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the season 2021 data onto predictor and gets top players\n",
    "leaderboard1 = wholeseason(final_test_games, lm_1, selected_features, choice)\n",
    "leaderboard2 = wholeseason(final_test_games, lm_2, selected_features_2, choice)\n",
    "leaderboard3 = wholeseason(final_test_games, lm_3, selected_features_3, choice)\n",
    "leaderboard4 = wholeseason(final_test_games, lm_4, selected_features_4, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Oliver Wines', 34),\n",
       " ('Jack Steele', 33),\n",
       " ('Christian Petracca', 30),\n",
       " ('Clayton Oliver', 28),\n",
       " ('Darcy Parish', 28),\n",
       " ('Jarryd Lyons', 27),\n",
       " ('Tom Mitchell', 27),\n",
       " ('Jackson Macrae', 27),\n",
       " ('Marcus Bontempelli', 26),\n",
       " ('Rory Laird', 23),\n",
       " ('Jake Stringer', 21),\n",
       " ('Cameron Guthrie', 20),\n",
       " ('Touk Miller', 20),\n",
       " ('Luke Parker', 20),\n",
       " ('Sam Walsh', 19)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard1[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Oliver Wines', 34),\n",
       " ('Jack Steele', 34),\n",
       " ('Clayton Oliver', 32),\n",
       " ('Jarryd Lyons', 28),\n",
       " ('Darcy Parish', 26),\n",
       " ('Marcus Bontempelli', 26),\n",
       " ('Rory Laird', 26),\n",
       " ('Christian Petracca', 25),\n",
       " ('Jackson Macrae', 25),\n",
       " ('Tom Mitchell', 24),\n",
       " ('Cameron Guthrie', 21),\n",
       " ('Touk Miller', 21),\n",
       " ('Sam Walsh', 20),\n",
       " ('Luke Parker', 20),\n",
       " ('Dominic Sheed', 19)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard2[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Oliver Wines', 34),\n",
       " ('Jack Steele', 34),\n",
       " ('Clayton Oliver', 31),\n",
       " ('Tom Mitchell', 30),\n",
       " ('Christian Petracca', 29),\n",
       " ('Darcy Parish', 28),\n",
       " ('Marcus Bontempelli', 27),\n",
       " ('Jackson Macrae', 26),\n",
       " ('Jarryd Lyons', 25),\n",
       " ('Rory Laird', 25),\n",
       " ('Touk Miller', 21),\n",
       " ('Cameron Guthrie', 20),\n",
       " ('Dominic Sheed', 20),\n",
       " ('Thomas Liberatore', 19),\n",
       " ('Sam Walsh', 19)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard3[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Oliver Wines', 34),\n",
       " ('Jack Steele', 34),\n",
       " ('Clayton Oliver', 32),\n",
       " ('Jarryd Lyons', 28),\n",
       " ('Darcy Parish', 26),\n",
       " ('Marcus Bontempelli', 26),\n",
       " ('Rory Laird', 26),\n",
       " ('Christian Petracca', 25),\n",
       " ('Jackson Macrae', 25),\n",
       " ('Tom Mitchell', 24),\n",
       " ('Cameron Guthrie', 21),\n",
       " ('Touk Miller', 21),\n",
       " ('Sam Walsh', 20),\n",
       " ('Luke Parker', 20),\n",
       " ('Dominic Sheed', 19)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard4[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Predictor's r scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23298806127226634\n",
      "0.23093336046383292\n",
      "0.23127768790264824\n",
      "0.23093336046383292\n"
     ]
    }
   ],
   "source": [
    "print(lm_1.score(traindata_x_1, traindata_y_1))\n",
    "print(lm_2.score(traindata_x_2, traindata_y_2))\n",
    "print(lm_3.score(traindata_x_3, traindata_y_3))\n",
    "print(lm_4.score(traindata_x_4, traindata_y_4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
